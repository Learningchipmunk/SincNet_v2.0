{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a newer version of SincNet with updated Loading and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa \n",
    "import librosa.display\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local files imports:\n",
    "from Models import MLP, flip, MainNet\n",
    "from Models import SincNet as CNN \n",
    "from Models import SincNet2D as CNN2D\n",
    "from utils import Optimizers, Schedulers, Dataset, plot_grad_flow, NLLL_OneHot, InitOptimizer, test_2D_raise_or_run\n",
    "from read_conf_files import read_conf\n",
    "from ipython_exit import exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Graphics Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting Cuda device... \t\tCuda was selected successfully!\n"
     ]
    }
   ],
   "source": [
    "Desired_cuda_device_number = 0\n",
    "\n",
    "print(\"Selecting Cuda device... \\t\\t\", end=\"\")\n",
    "if torch.cuda.is_available(): # we'll use cuda\n",
    "    device = \"cuda:\"+str(Desired_cuda_device_number)\n",
    "    torch.cuda.set_device(device)\n",
    "    if(torch.cuda.current_device() == Desired_cuda_device_number and torch.cuda.is_available()):\n",
    "        print(\"Cuda was selected successfully!\")\n",
    "    else:\n",
    "        print(\"Cuda was not selected successfully...\")\n",
    "else:\n",
    "    print(\"Cuda device(s) is(are) not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf loader:\n",
    "\n",
    "[Link to documentation](https://docs.python.org/3/library/configparser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`read_conf` was successfully imported from read_conf_files.py!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"def read_conf(config_file_path):\n",
    "    # Removed the possibility of executing with --cfg = path\n",
    "    # Instead we feed it directly\n",
    "\n",
    "    # Initializing dummy class with cfg folder path:\n",
    "    options = Options(config_file_path)\n",
    "\n",
    "    # Reading the config file with config parser\n",
    "    Config = ConfigParser.ConfigParser()\n",
    "    Config.read(options.cfg)\n",
    "\n",
    "    #[data]\n",
    "    options.tr_lst=Config.get('data', 'tr_lst')\n",
    "    options.te_lst=Config.get('data', 'te_lst')\n",
    "    options.lab_dict=Config.get('data', 'lab_dict')\n",
    "    options.data_folder=Config.get('data', 'data_folder')\n",
    "    options.output_folder=Config.get('data', 'output_folder')\n",
    "    options.pt_file=Config.get('data', 'pt_file')\n",
    "\n",
    "    #[windowing]\n",
    "    options.fs=Config.get('windowing', 'fs')\n",
    "    options.cw_len=Config.get('windowing', 'cw_len')\n",
    "    options.cw_shift=Config.get('windowing', 'cw_shift')\n",
    "\n",
    "    if('cnn2D' in Config.sections()):\n",
    "        #[cnn2D]\n",
    "        options.is_conv2D = True\n",
    "        options.cnn_N_filt=Config.get('cnn2D', 'cnn_N_filt')\n",
    "        options.cnn_len_filt_W=Config.get('cnn2D', 'cnn_len_filt_W')\n",
    "        options.cnn_len_filt_H=Config.get('cnn2D', 'cnn_len_filt_H')\n",
    "        options.cnn_energy_L=Config.get('cnn2D', 'cnn_energy_L')\n",
    "        options.cnn_energy_stride=Config.get('cnn2D', 'cnn_energy_stride')\n",
    "        options.cnn_max_pool_len_W=Config.get('cnn2D', 'cnn_max_pool_len_W')\n",
    "        options.cnn_max_pool_len_H=Config.get('cnn2D', 'cnn_max_pool_len_H')\n",
    "        options.cnn_use_laynorm_inp=Config.get('cnn2D', 'cnn_use_laynorm_inp')\n",
    "        options.cnn_use_batchnorm_inp=Config.get('cnn2D', 'cnn_use_batchnorm_inp')\n",
    "        options.cnn_use_laynorm=Config.get('cnn2D', 'cnn_use_laynorm')\n",
    "        options.cnn_use_batchnorm=Config.get('cnn2D', 'cnn_use_batchnorm')\n",
    "        options.cnn_act=Config.get('cnn2D', 'cnn_act')\n",
    "        options.cnn_drop=Config.get('cnn2D', 'cnn_drop')\n",
    "    else:\n",
    "        #[cnn]\n",
    "        options.is_conv2D = False\n",
    "        options.cnn_N_filt=Config.get('cnn', 'cnn_N_filt')\n",
    "        options.cnn_len_filt=Config.get('cnn', 'cnn_len_filt')\n",
    "        options.cnn_max_pool_len=Config.get('cnn', 'cnn_max_pool_len')\n",
    "        options.cnn_use_laynorm_inp=Config.get('cnn', 'cnn_use_laynorm_inp')\n",
    "        options.cnn_use_batchnorm_inp=Config.get('cnn', 'cnn_use_batchnorm_inp')\n",
    "        options.cnn_use_laynorm=Config.get('cnn', 'cnn_use_laynorm')\n",
    "        options.cnn_use_batchnorm=Config.get('cnn', 'cnn_use_batchnorm')\n",
    "        options.cnn_act=Config.get('cnn', 'cnn_act')\n",
    "        options.cnn_drop=Config.get('cnn', 'cnn_drop')\n",
    "\n",
    "\n",
    "    #[dnn]\n",
    "    options.fc_lay=Config.get('dnn', 'fc_lay')\n",
    "    options.fc_drop=Config.get('dnn', 'fc_drop')\n",
    "    options.fc_use_laynorm_inp=Config.get('dnn', 'fc_use_laynorm_inp')\n",
    "    options.fc_use_batchnorm_inp=Config.get('dnn', 'fc_use_batchnorm_inp')\n",
    "    options.fc_use_batchnorm=Config.get('dnn', 'fc_use_batchnorm')\n",
    "    options.fc_use_laynorm=Config.get('dnn', 'fc_use_laynorm')\n",
    "    options.fc_act=Config.get('dnn', 'fc_act')\n",
    "\n",
    "    #[class]\n",
    "    options.class_lay=Config.get('class', 'class_lay')\n",
    "    options.class_drop=Config.get('class', 'class_drop')\n",
    "    options.class_use_laynorm_inp=Config.get('class', 'class_use_laynorm_inp')\n",
    "    options.class_use_batchnorm_inp=Config.get('class', 'class_use_batchnorm_inp')\n",
    "    options.class_use_batchnorm=Config.get('class', 'class_use_batchnorm')\n",
    "    options.class_use_laynorm=Config.get('class', 'class_use_laynorm')\n",
    "    options.class_act=Config.get('class', 'class_act')\n",
    "\n",
    "    #[optimization]\n",
    "    if('optimization' in Config.sections()):\n",
    "        if 'optimizer_type' in Config['optimization']:\n",
    "            options.optimizer_type=Config.get('optimization', 'optimizer_type')\n",
    "        else:\n",
    "            options.optimizer_type='RMSprop'\n",
    "            print(\"You did not specify the value of `optimizer_type`, it is set to {}.\".format(options.optimizer_type))\n",
    "        \n",
    "        options.lr=Config.get('optimization', 'lr')\n",
    "\n",
    "        ## use_scheduler:\n",
    "        if 'use_scheduler' in Config['optimization']:\n",
    "            options.use_scheduler=Config.get('optimization', 'use_scheduler')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `use_scheduler`, it is set to False.\")\n",
    "            options.use_scheduler='False'\n",
    "\n",
    "        ## scheduler_type:\n",
    "        if 'scheduler_type' in Config['optimization']:\n",
    "            options.scheduler_type=Config.get('optimization', 'scheduler_type')\n",
    "        else:\n",
    "            options.scheduler_type='ReduceLROnPlateau'\n",
    "            print(\"You did not specify the value of `scheduler_type`, it is set to {}.\".format(options.scheduler_type))    \n",
    "        \n",
    "        ## scheduler_patience:\n",
    "        if 'scheduler_patience' in Config['optimization']:\n",
    "            options.scheduler_patience=Config.get('optimization', 'scheduler_patience')\n",
    "        else:\n",
    "            options.scheduler_patience=2\n",
    "            print(\"You did not specify the value of `scheduler_patience`, it is set to {}.\".format(options.scheduler_patience))\n",
    "\n",
    "        ## scheduler_factor:\n",
    "        if 'scheduler_factor' in Config['optimization']:\n",
    "            options.scheduler_factor=Config.get('optimization', 'scheduler_factor')\n",
    "        else:\n",
    "            options.scheduler_factor=0.5\n",
    "            print(\"You did not specify the value of `scheduler_factor`, it is set to {}.\".format(options.scheduler_factor))\n",
    "\n",
    "\n",
    "        options.batch_size=Config.get('optimization', 'batch_size')\n",
    "\n",
    "        ## Batch_dev:\n",
    "        if 'Batch_dev' in Config['optimization']:\n",
    "            options.Batch_dev=Config.get('optimization', 'Batch_dev')\n",
    "        else:\n",
    "            options.Batch_dev=32\n",
    "            print(\"You did not specify the value of `Batch_dev`, it is set to {}.\".format(options.Batch_dev))\n",
    "\n",
    "        ## patience:\n",
    "        if 'patience' in Config['optimization']:\n",
    "            options.patience=Config.get('optimization', 'patience')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `patience`, it is set to 7.\")\n",
    "            options.patience=7\n",
    "\n",
    "        options.N_epochs=Config.get('optimization', 'N_epochs')\n",
    "        options.N_batches=Config.get('optimization', 'N_batches')\n",
    "        options.N_eval_epoch=Config.get('optimization', 'N_eval_epoch')\n",
    "        \n",
    "        ## train_acc_period:\n",
    "        if 'train_acc_period' in Config['optimization']:\n",
    "                options.train_acc_period=Config.get('optimization', 'train_acc_period')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `train_acc_period`, it is set to 5.\")\n",
    "            options.train_acc_period=5\n",
    "        \n",
    "        ## fact_amp:        \n",
    "        if 'fact_amp' in Config['optimization']:\n",
    "                options.fact_amp=Config.get('optimization', 'fact_amp')\n",
    "        else:\n",
    "            options.fact_amp=0.2\n",
    "            print(\"You did not specify the value of `fact_amp`, it is set to {}.\".format(options.fact_amp))\n",
    "        \n",
    "        ## use_mixup:\n",
    "        if 'use_mixup' in Config['optimization']:\n",
    "            options.use_mixup=Config.get('optimization', 'use_mixup')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `use_mixup`, it is set to False.\")\n",
    "            options.use_mixup='False'\n",
    "        \n",
    "        ## mixup_batch_prop:        \n",
    "        if 'mixup_batch_prop' in Config['optimization']:\n",
    "            options.mixup_batch_prop=Config.get('optimization', 'mixup_batch_prop')\n",
    "        else:\n",
    "            options.mixup_batch_prop=float(1.0) if options.use_mixup=='True' else float(0.0)\n",
    "            print(\"You did not specify the value of `mixup_batch_prop`, it is set to {}%.\".format(options.mixup_batch_prop*100))\n",
    "        \n",
    "        ## beta_coef:\n",
    "        if 'beta_coef' in Config['optimization']:\n",
    "            options.beta_coef=Config.get('optimization', 'beta_coef')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `beta_coef`, it is set to 0.4.\")\n",
    "            options.beta_coef=0.4\n",
    "        \n",
    "        ## same_classes:        \n",
    "        if 'same_classes' in Config['optimization']:\n",
    "            options.same_classes=Config.get('optimization', 'same_classes')\n",
    "        else:\n",
    "            options.same_classes='False'\n",
    "            print(\"You did not specify the value of `same_classes`, it is set to {}.\".format(options.same_classes))\n",
    "            if(\"True\" in options.use_mixup):\n",
    "                print(\"Warning: you are using mixup but you did not mention which type in config file. \\n\"+\n",
    "                    \"By default it will be set to False. You are advised to add a same_class attribute to your cfg file and set it to True or False.\")    \n",
    "\n",
    "            \n",
    "        options.seed=Config.get('optimization', 'seed')\n",
    "    else:\n",
    "        print(\"Error, you did not specify optimization parameters in your cfg. Consequently, the code won't run...\")\n",
    "        \n",
    "    #[Misc]\n",
    "    ## In SincNet, we must always use SincConv_fast, it is the whole point of SincNet. But, just for testing, we added the possibility to deactivate it. \n",
    "    ## This is why we do not prompt the user if he does not have a `Misc`section.\n",
    "    options.use_SincConv_fast='True'\n",
    "    if('Misc' in Config.sections()):\n",
    "        ## use_SincConv_fast:        \n",
    "        if 'use_SincConv_fast' in Config['Misc']:\n",
    "            options.use_SincConv_fast=Config.get('Misc', 'use_SincConv_fast')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `use_SincConv_fast`, but don't worry, it is set to {}.\".format(options.use_SincConv_fast))\n",
    "\n",
    "\n",
    "    return options\n",
    "\"\"\"\n",
    "\n",
    "## read_conf is now imported from read_conf_files.py:\n",
    "imported = \"`read_conf` was successfully imported from read_conf_files.py!\" if 'read_conf' in dir() else \"read_conf was not successfully imported from read_conf_files.py!\"\n",
    "print(imported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did not specify the value of `scheduler_type`, it is set to ReduceLROnPlateau.\n",
      "exp/SincNet_DCASE_v2.0/test\n",
      "Data/Audio_Tensors/Train/Preprocessed_withEnergy_AudioTensors_Window1000ms_Random0Padding/\n"
     ]
    }
   ],
   "source": [
    "# Config path location\n",
    "config_file_path = \"cfg/test.cfg\"\n",
    "\n",
    "# Reading cfg file and storing its parameters into options :\n",
    "options=read_conf(config_file_path)\n",
    "\n",
    "print(options.output_folder)\n",
    "print(options.data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and storing all the info from the config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are the config data processing functions used in data_io:\n",
    "\n",
    "# Converts string to bool:\n",
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "    else:\n",
    "         raise ValueError \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains the config of a 1D convolutional network.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#[data]\n",
    "tr_lst=options.tr_lst\n",
    "te_lst=options.te_lst\n",
    "pt_file=options.pt_file\n",
    "class_dict_file=options.lab_dict\n",
    "data_folder=options.data_folder\n",
    "output_folder=options.output_folder\n",
    "\n",
    "#[windowing]\n",
    "fs=int(options.fs)\n",
    "cw_len=int(options.cw_len)\n",
    "cw_shift=int(options.cw_shift)\n",
    "\n",
    "is_conv2D = options.is_conv2D\n",
    "conv_type = '2D' if is_conv2D else '1D'\n",
    "print(\"The file contains the config of a {} convolutional network.\".format(conv_type))\n",
    "if is_conv2D:\n",
    "    #[cnn2D]\n",
    "    cnn_N_filt=list(map(int, options.cnn_N_filt.split(',')))\n",
    "    cnn_len_filt_W=list(map(int, options.cnn_len_filt_W.split(',')))\n",
    "    cnn_len_filt_H=list(map(int, options.cnn_len_filt_H.split(',')))\n",
    "    cnn_energy_L=int(options.cnn_energy_L)\n",
    "    cnn_energy_stride=int(options.cnn_energy_stride)\n",
    "    cnn_max_pool_len_W=list(map(int, options.cnn_max_pool_len_W.split(',')))\n",
    "    cnn_max_pool_len_H=list(map(int, options.cnn_max_pool_len_H.split(',')))\n",
    "else:\n",
    "    #[cnn]\n",
    "    cnn_N_filt=list(map(int, options.cnn_N_filt.split(',')))\n",
    "    cnn_len_filt=list(map(int, options.cnn_len_filt.split(',')))\n",
    "    cnn_max_pool_len=list(map(int, options.cnn_max_pool_len.split(',')))\n",
    "\n",
    "cnn_use_laynorm_inp=str_to_bool(options.cnn_use_laynorm_inp)\n",
    "cnn_use_batchnorm_inp=str_to_bool(options.cnn_use_batchnorm_inp)\n",
    "cnn_use_laynorm=list(map(str_to_bool, options.cnn_use_laynorm.split(',')))\n",
    "cnn_use_batchnorm=list(map(str_to_bool, options.cnn_use_batchnorm.split(',')))\n",
    "cnn_act=list(map(str, options.cnn_act.split(',')))\n",
    "cnn_drop=list(map(float, options.cnn_drop.split(',')))\n",
    "\n",
    "    \n",
    "\n",
    "#[dnn]\n",
    "fc_lay=list(map(int, options.fc_lay.split(',')))\n",
    "fc_drop=list(map(float, options.fc_drop.split(',')))\n",
    "fc_use_laynorm_inp=str_to_bool(options.fc_use_laynorm_inp)\n",
    "fc_use_batchnorm_inp=str_to_bool(options.fc_use_batchnorm_inp)\n",
    "fc_use_batchnorm=list(map(str_to_bool, options.fc_use_batchnorm.split(',')))\n",
    "fc_use_laynorm=list(map(str_to_bool, options.fc_use_laynorm.split(',')))\n",
    "fc_act=list(map(str, options.fc_act.split(',')))\n",
    "\n",
    "#[class]\n",
    "class_lay=list(map(int, options.class_lay.split(',')))\n",
    "class_drop=list(map(float, options.class_drop.split(',')))\n",
    "class_use_laynorm_inp=str_to_bool(options.class_use_laynorm_inp)\n",
    "class_use_batchnorm_inp=str_to_bool(options.class_use_batchnorm_inp)\n",
    "class_use_batchnorm=list(map(str_to_bool, options.class_use_batchnorm.split(',')))\n",
    "class_use_laynorm=list(map(str_to_bool, options.class_use_laynorm.split(',')))\n",
    "class_act=list(map(str, options.class_act.split(',')))\n",
    "\n",
    "\n",
    "#[optimization]\n",
    "optimizer_type=str(options.optimizer_type)\n",
    "lr=float(options.lr)\n",
    "use_scheduler = str_to_bool(options.use_scheduler)\n",
    "scheduler_patience = int(options.scheduler_patience)\n",
    "scheduler_factor = float(options.scheduler_factor)\n",
    "batch_size=int(options.batch_size)\n",
    "Batch_dev=int(options.Batch_dev)\n",
    "patience=int(options.patience)\n",
    "N_epochs=int(options.N_epochs)\n",
    "N_batches=int(options.N_batches)\n",
    "N_eval_epoch=int(options.N_eval_epoch)\n",
    "train_acc_period=int(options.train_acc_period)\n",
    "fact_amp=float(options.fact_amp)\n",
    "use_mixup=str_to_bool(options.use_mixup)\n",
    "beta_coef=float(options.beta_coef)\n",
    "mixup_batch_prop=float(options.mixup_batch_prop)\n",
    "same_classes=str_to_bool(options.same_classes)\n",
    "seed=int(options.seed)\n",
    "\n",
    "\n",
    "#[Misc]\n",
    "use_SincConv_fast = str_to_bool(options.use_SincConv_fast)\n",
    "\n",
    "## The location of all the wav files are stored here:\n",
    "# training list\n",
    "tensors_lst_tr = np.load(tr_lst)\n",
    "snt_tr=len(tensors_lst_tr)\n",
    "\n",
    "# test list\n",
    "tensors_lst_te = np.load(te_lst)\n",
    "snt_te=len(tensors_lst_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates the out folder and initializes the networks with cfg file info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (wx): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=41, bias=True)\n",
       "  )\n",
       "  (bn): ModuleList(\n",
       "    (0): BatchNorm1d(41, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (ln): ModuleList(\n",
       "    (0): LayerNorm()\n",
       "  )\n",
       "  (act): ModuleList(\n",
       "    (0): LogSoftmax()\n",
       "  )\n",
       "  (drop): ModuleList(\n",
       "    (0): Dropout(p=0.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Folder creation\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    " \n",
    "    \n",
    "    \n",
    "# setting seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# loss function\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "\n",
    "  \n",
    "# Converting context and shift in samples\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "wshift=int(fs*cw_shift/1000.00)\n",
    "\n",
    "\n",
    "\n",
    "# Feature extractor CNN\n",
    "if is_conv2D:\n",
    "    CNN_arch = {'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt_W': cnn_len_filt_W,\n",
    "            'cnn_len_filt_H': cnn_len_filt_H,\n",
    "            'cnn_energy_L': cnn_energy_L,\n",
    "            'cnn_energy_stride': cnn_energy_stride,\n",
    "            'cnn_max_pool_len_W': cnn_max_pool_len_W,\n",
    "            'cnn_max_pool_len_H': cnn_max_pool_len_H,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,\n",
    "            'use_SincConv_fast': use_SincConv_fast,          \n",
    "            }\n",
    "else:\n",
    "    CNN_arch = {'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt': cnn_len_filt,\n",
    "            'cnn_max_pool_len':cnn_max_pool_len,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,\n",
    "            'use_SincConv_fast': use_SincConv_fast,                      \n",
    "            }\n",
    "\n",
    "## Initializes SincNet:\n",
    "CNN_net=CNN2D(CNN_arch) if is_conv2D else CNN(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "\n",
    "# Loading label dictionary\n",
    "lab_dict=np.load(class_dict_file).item()\n",
    "\n",
    "\n",
    "## First DNN, follows the config from the section [dnn] in .cfg file\n",
    "DNN1_arch = {'input_dim': CNN_net.out_dim,\n",
    "          'fc_lay': fc_lay,\n",
    "          'fc_drop': fc_drop, \n",
    "          'fc_use_batchnorm': fc_use_batchnorm,\n",
    "          'fc_use_laynorm': fc_use_laynorm,\n",
    "          'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "          'fc_act': fc_act,\n",
    "          }\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "\n",
    "## Last trainable layer, has softmax as activation function see section [class] in .cfg\n",
    "DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "          'fc_lay': class_lay,\n",
    "          'fc_drop': class_drop, \n",
    "          'fc_use_batchnorm': class_use_batchnorm,\n",
    "          'fc_use_laynorm': class_use_laynorm,\n",
    "          'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "          'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates the main net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainNet(\n",
       "  (CNN_net): SincNet(\n",
       "    (conv): ModuleList(\n",
       "      (0): SincConv_fast()\n",
       "      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n",
       "      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n",
       "      (3): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(80, eps=8450, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(60, eps=2815, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(60, eps=937, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(60, eps=311, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "      (2): LayerNorm()\n",
       "      (3): LayerNorm()\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): LeakyReLU(negative_slope=0.2)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.0)\n",
       "      (1): Dropout(p=0.0)\n",
       "      (2): Dropout(p=0.0)\n",
       "      (3): Dropout(p=0.0)\n",
       "    )\n",
       "    (ln0): LayerNorm()\n",
       "  )\n",
       "  (DNN1_net): MLP(\n",
       "    (wx): ModuleList(\n",
       "      (0): Linear(in_features=18660, out_features=1516, bias=True)\n",
       "      (1): Linear(in_features=1516, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(1516, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "      (2): LayerNorm()\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): PReLU(num_parameters=1)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.3)\n",
       "      (1): Dropout(p=0.3)\n",
       "      (2): Dropout(p=0.3)\n",
       "    )\n",
       "    (ln0): LayerNorm()\n",
       "  )\n",
       "  (DNN2_net): MLP(\n",
       "    (wx): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=41, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(41, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): LogSoftmax()\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.0)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_net = MainNet(CNN_net, DNN1_net, DNN2_net)\n",
    "Main_net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our dataset variant:\n",
    "\n",
    ">We use the saved tensors file on Hard Disk to save RAM. Has Random chunk generator and mixup implemented(see training fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the datasets:\n",
    "\n",
    "train_dataset      = Dataset(tensors_lst_tr, lab_dict, data_folder, wlen, fact_amp = fact_amp, wshift = 0, using_mixup=use_mixup, beta_coef=beta_coef, mixup_prop=mixup_batch_prop, sameClasses = same_classes, train = True, is_fastai=False)\n",
    "valid_dataset      = Dataset(tensors_lst_te, lab_dict, data_folder, wlen, fact_amp = 0, wshift = wshift, train = False, is_fastai=False)\n",
    "# dataset for confusion matrix:\n",
    "#valid_dataset_conf = Dataset(tensors_lst_te, lab_dict, data_folder, wlen, 0.2, wshift = wshift, eval_mode= True, train = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.1079, -0.0110,  0.1376,  ...,  0.0109, -0.0312,  0.0203]), 30)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.get_item_randomly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(valid_dataset.tensor_by_class_dict)\n",
    "#print(valid_dataset.list_IDs_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the dataloaders for training dataset and validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the loaders:\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## Batchsize can only be 1 for valid_loader because each tensor has a different shape...\n",
    "valid_loader  = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                          batch_size=Batch_dev,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0175,  0.0365,  0.1049,  ...,  0.0056,  0.0070,  0.0067],\n",
      "        [ 0.3105,  0.2418,  0.1631,  ..., -0.1060, -0.0816, -0.0943],\n",
      "        [ 0.1206,  0.0978,  0.0496,  ..., -0.0176, -0.0174, -0.0167],\n",
      "        ...,\n",
      "        [ 0.2094,  0.2054,  0.2000,  ..., -0.0005, -0.0004, -0.0005],\n",
      "        [ 0.0908,  0.0901,  0.0816,  ...,  0.2116,  0.2482,  0.2648],\n",
      "        [-0.1312, -0.1311, -0.1316,  ...,  0.0000,  0.0000,  0.0000]]) tensor([ 3, 37,  8, 11, 26,  7,  4,  5,  1,  1,  2, 38, 10, 14,  6,  1,  2, 26,\n",
      "        17,  1,  2, 29, 15, 15, 14,  0,  4, 40, 35,  5, 15, 21])\n",
      "torch.Size([32, 25600])\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "if(use_mixup):\n",
    "    X, labels, used_mixup = next(iter(train_loader))\n",
    "    print(used_mixup.sum().item()/X.size(0))# batch_size = X.size(0)\n",
    "else:\n",
    "    X, labels = next(iter(train_loader))\n",
    "\n",
    "print(X, labels)\n",
    "print(X.shape)\n",
    "print(X.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1218, -0.1462, -0.1257,  ..., -0.2727, -0.3080, -0.3364],\n",
      "        [ 0.1029,  0.0696,  0.0426,  ...,  0.1946,  0.1648,  0.1294],\n",
      "        [-0.2260, -0.2151, -0.1955,  ..., -0.1181, -0.1349, -0.1238],\n",
      "        ...,\n",
      "        [-0.1387, -0.1330, -0.1819,  ..., -0.0331, -0.0456, -0.0531],\n",
      "        [ 0.0393,  0.0207,  0.0356,  ...,  0.1600,  0.1813,  0.1893],\n",
      "        [ 0.0207, -0.1766, -0.1892,  ..., -0.0103, -0.0624, -0.0856]]) \n",
      " tensor([33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 38, 38, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38])\n",
      "torch.Size([32, 25600])\n",
      "torch.Size([32])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "X_valid, labels_valid, tensor_ids = next(iter(valid_loader))\n",
    "print(X_valid, \"\\n\", labels_valid)\n",
    "print(X_valid.shape)\n",
    "print(labels_valid.shape)\n",
    "print(tensor_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 19]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Algorithm that detects a shift in file and stores the index of first appearence in list:\n",
    "section = []\n",
    "ids_list = []\n",
    "current_idx = tensor_ids[0].item()\n",
    "ids_list.append(current_idx)\n",
    "for i, el in enumerate(tensor_ids):\n",
    "    current_el = el.item()\n",
    "    if current_el != current_idx:\n",
    "        current_idx = current_el\n",
    "        ids_list.append(current_idx)\n",
    "        section.append(i - sum(section))\n",
    "\n",
    "## Last section is added:    \n",
    "section.append(X.size(0) - sum(section))\n",
    "print(section)\n",
    "ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12969830400000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated('cuda') * 1.e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training set Spectrograms (Only for SincNet2D): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5fa7e7a00107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnnAudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "\n",
    "    \n",
    "from nnAudio import Spectrogram\n",
    "\n",
    "# Mel spectgrogram is initialized with same parameters as SincConv fast!\n",
    "spec_layer = Spectrogram.MelSpectrogram(n_fft=CNN_arch[\"cnn_energy_L\"], n_mels=CNN_arch[\"cnn_N_filt\"][0], hop_length=CNN_arch[\"cnn_energy_stride\"],#n_mels=CNN_arch[\"cnn_N_filt\"][0] in order to be the same with SincNet \n",
    "                      window='hann', center=True, pad_mode='reflect', \n",
    "                      sr = CNN_arch[\"fs\"], device=device, trainable_mel=False, trainable_STFT=False) # Initializing the model with device='cuda:0'\n",
    "    \n",
    "\n",
    "# Fonction that changes the scale of the power:\n",
    "def tensorLogScale(tensor):\n",
    "    # Constant that translates all values to 10^-3\n",
    "    eps = 1e-3\n",
    "\n",
    "    # log(eps + pow):\n",
    "    return (eps + tensor).log10()\n",
    "\n",
    "def PrintSpectrograms2(specs, specType):\n",
    "\n",
    "    N_audios = specs.size(0)\n",
    "    N_column = 4\n",
    "\n",
    "    fig, ax = plt.subplots(int(np.ceil(N_audios/N_column)), N_column, figsize=(14, 7),\n",
    "                          subplot_kw={'xticks': [], 'yticks': []})   \n",
    "\n",
    "    for i,spec in enumerate(specs):\n",
    "\n",
    "        ## Position in the axes grid:\n",
    "        axi, axj = int(i/N_column), i%N_column\n",
    "\n",
    "        ## imshow only works on CPU tensors:\n",
    "        if spec.is_cuda:\n",
    "            spec = spec.cpu()\n",
    "\n",
    "        # Here, we control the values of the ordinate and abscissa with the variable extent:\n",
    "        pos = ax[axi][axj].imshow(spec, origin='lower', cmap='jet', aspect='auto')\n",
    "        #ax[axi][axj].set_xlabel('Time frames')\n",
    "        #ax[axi][axj].set_ylabel('Frequency [Hz]')\n",
    "\n",
    "        # Plot colorbar\n",
    "        fig.colorbar(pos, ax=ax[axi][axj])\n",
    "\n",
    "    # Places the spectrograms next to each other:\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0, hspace=0)\n",
    "\n",
    "    # Writes the title:\n",
    "    fig.suptitle(\"Image representation of a \" + specType + \" Spectrogram for each audio file:\", fontsize=20, y=1.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0794acf30a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPrintSpectrograms2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorLogScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Log Mel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "    \n",
    "\n",
    "PrintSpectrograms2(tensorLogScale(spec_layer(X.cuda())), \"Log Mel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark:\n",
    "\n",
    "    Differences occur because of LayerNorm and hann window!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for SincNet2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8843a2b68f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "    \n",
    "\n",
    "test_net = CNN2D(CNN_arch, print_spec = True)\n",
    "test_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-212a2d1e7535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "\n",
    "\n",
    "test_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3523b7b5e7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(test_net.forward(X.cuda()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e3ad48df0bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "\n",
    "test_net.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raising exception and exiting cell.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b22f91f68ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Exits form cell if the Network is not 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_2D_raise_or_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_conv2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SincNet_DCASE_v2.0/utils.py\u001b[0m in \u001b[0;36mtest_2D_raise_or_run\u001b[0;34m(is_conv2D)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_conv2D\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising exception and exiting cell.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current Network is not `SincNet2D` therefore the code won't be able to run! \\nExited cell safely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The current Network is not `SincNet2D` therefore the code won't be able to run! \nExited cell safely."
     ]
    }
   ],
   "source": [
    "## Exits form cell if the Network is not 2D\n",
    "test_2D_raise_or_run(is_conv2D)\n",
    "\n",
    "del test_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 41])\n",
      "{'input_dim': 25600, 'fs': 32000, 'cnn_N_filt': [80, 60, 60, 60], 'cnn_len_filt': [251, 5, 5, 5], 'cnn_max_pool_len': [3, 3, 3, 3], 'cnn_use_laynorm_inp': True, 'cnn_use_batchnorm_inp': False, 'cnn_use_laynorm': [True, True, True, True], 'cnn_use_batchnorm': [False, False, False, False], 'cnn_act': ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'], 'cnn_drop': [0.0, 0.0, 0.0, 0.0], 'use_SincConv_fast': True}\n"
     ]
    }
   ],
   "source": [
    "Main_net.eval()\n",
    "with torch.no_grad():\n",
    "    print(Main_net.forward(X.cuda()).shape)\n",
    "Main_net.train()\n",
    "print(CNN_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate finder:\n",
    "\n",
    "The thread where the idea originated from is accessible [here.](https://discuss.pytorch.org/t/get-the-best-learning-rate-automatically/58269/7) <br>\n",
    "The thread where the code originated from is accessible [here.](https://forums.fast.ai/t/automated-learning-rate-suggester/44199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the tools from fastai:\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset.is_fastai = True\n",
    "\n",
    "databunch = DataBunch.create(train_dataset, valid_dataset, bs=32, device = torch.device('cuda'))\n",
    "learn = Learner(databunch, Main_net, loss_func = cost, metrics = accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_appropriate_lr(model:Learner, lr_diff:int = 15, loss_threshold:float = .05, adjust_value:float = 1, plot:bool = False) -> float:\n",
    "    #Run the Learning Rate Finder\n",
    "    model.lr_find()\n",
    "    \n",
    "    #Get loss values and their corresponding gradients, and get lr values\n",
    "    losses = np.array(model.recorder.losses)\n",
    "    assert(lr_diff < len(losses))\n",
    "    loss_grad = np.gradient(losses)\n",
    "    lrs = model.recorder.lrs\n",
    "    \n",
    "    #Search for index in gradients where loss is lowest before the loss spike\n",
    "    #Initialize right and left idx using the lr_diff as a spacing unit\n",
    "    #Set the local min lr as -1 to signify if threshold is too low\n",
    "    r_idx = -1\n",
    "    l_idx = r_idx - lr_diff\n",
    "    while (l_idx >= -len(losses)) and (abs(loss_grad[r_idx] - loss_grad[l_idx]) > loss_threshold):\n",
    "        local_min_lr = lrs[l_idx]\n",
    "        r_idx -= 1\n",
    "        l_idx -= 1\n",
    "\n",
    "    lr_to_use = local_min_lr * adjust_value\n",
    "    \n",
    "    if plot:\n",
    "        # plots the gradients of the losses in respect to the learning rate change\n",
    "        plt.plot(loss_grad)\n",
    "        plt.plot(len(losses)+l_idx, loss_grad[l_idx],markersize=10,marker='o',color='red')\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Index of LRs\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(np.log10(lrs), losses)\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Log 10 Transform of Learning Rate\")\n",
    "        loss_coord = np.interp(np.log10(lr_to_use), np.log10(lrs), losses)\n",
    "        plt.plot(np.log10(lr_to_use), loss_coord, markersize=10,marker='o',color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    return lr_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='90' class='' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      38.14% [90/236 00:10<00:17 12.6175]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fast ai modules finish here, so we switch back to old dataset:\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "valid_dataset.is_fastai = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='89' class='' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      37.71% [89/236 00:10<00:17 11.6540]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022908676527677745\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dataset.is_fastai = True\n",
    "lr = find_appropriate_lr(learn, plot=True)\n",
    "print(lr)\n",
    "valid_dataset.is_fastai = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"learn.fit(1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim and Net learning:\n",
    "\n",
    "For a **theoretical perspective** of optimization functions, see <cite>Goodfellow, Ian. Deep Learning. Cambridge, Massachusetts, The MIT Press, Publication Date</cite> chapter 8, paragraph 5.\n",
    "<br>\n",
    "For the **pytorch documentation** of these functions see [here.](https://pytorch.org/docs/stable/optim.html)<br>\n",
    "For a brief explication on each optimizer see [here](https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/#:~:text=While%20momentum%20accelerates%20our%20search,of%20both%20Momentum%20and%20RMSProp.). **RMSProp vs Adam**, both have adaptive Learning Rates. \n",
    "![Optimization evolution figure](Images/optims.jpg)<br>\n",
    "<center><b>Thanks Paul for the Image!</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing optimizers... \t\t"
     ]
    }
   ],
   "source": [
    "print(\"Initializing optimizers... \\t\\t\", end=\"\")\n",
    "# Added momentum:\n",
    "momentum = 0.9 if use_mixup else 0\n",
    "    \n",
    "# InitOptimizers\n",
    "optimizer_CNN  = InitOptimizer(optimizer_type, CNN_net.parameters(), lr=lr, momentum=momentum)#optim.RMSprop(CNN_net.parameters(), lr=lr,alpha=0.95, eps=1e-8, momentum=momentum) \n",
    "optimizer_DNN1 = InitOptimizer(optimizer_type, DNN1_net.parameters(), lr=lr, momentum=momentum)#optim.RMSprop(DNN1_net.parameters(), lr=lr,alpha=0.95, eps=1e-8, momentum=momentum) \n",
    "optimizer_DNN2 = InitOptimizer(optimizer_type, DNN2_net.parameters(), lr=lr, momentum=momentum)#optim.RMSprop(DNN2_net.parameters(), lr=lr,alpha=0.95, eps=1e-8, momentum=momentum) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimizers are ready!\n"
     ]
    }
   ],
   "source": [
    "# Puts the in the same wrapper:\n",
    "optimizers = Optimizers(optimizer_CNN, optimizer_DNN1, optimizer_DNN2)\n",
    "\n",
    "print(\"{} optimizers are ready!\".format(optimizer_type))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining schedulers for each optimizers:\n",
    "\n",
    "The documentation of the scheduler used can be accessed [here](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Initializing all schedulers for optims:\n",
    "scheduler_CNN  = optim.lr_scheduler.ReduceLROnPlateau(optimizer_CNN, mode='min', factor=scheduler_factor, patience=scheduler_patience, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "scheduler_DNN1 = optim.lr_scheduler.ReduceLROnPlateau(optimizer_DNN1, mode='min', factor=scheduler_factor, patience=scheduler_patience, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "scheduler_DNN2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer_DNN2, mode='min', factor=scheduler_factor, patience=scheduler_patience, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "#nbre of training batches per epoch:\n",
    "#nbre_batch_epoch = snt_tr / batch_size\n",
    "#step_in_epoch    = 8\n",
    "\n",
    "#base_lr = max_lr/4 for triangular\n",
    "#optim.lr_scheduler.CyclicLR(optimizer_CNN, base_lr=0.0001, max_lr=0.001, step_size_up=nbre_batch_epoch*step_in_epoch, step_size_down=None, mode='triangular2', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedulers = Schedulers(scheduler_CNN, scheduler_DNN1, scheduler_DNN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring the gradient:\n",
    "\n",
    "This code is taken from a pytorch discussion that you can find [here](https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063). \n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "   * We added `and (p.grad is not None)` to each function because some parameters are initialized and named but not learned or used. Therefore their grad is None and has no attribute abs()!\n",
    "   * It affects parameters like `bn.1.bias`who are initialized but not used in forward and disabled because the config file their are set as so in the config file. We chose to use layernorm instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple function, plots the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow_simple(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n) and (p.grad is not None):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex functions in order to plot hist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "## Gradient histogram rep, Calot's suggestion:\n",
    "def plot_grad_flow(named_parameters, plot_both = False):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n) and (p.grad is not None):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    \n",
    "    ## Plotting also lines like in plot_grad_flow_simple:\n",
    "    if(plot_both):\n",
    "        plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "        plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "        plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "        plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## Loaded the list of indexes I already created:\n",
    "dictOfLabels = np.load(\"data_lists/labelsToNumberDict.npy\").item()\n",
    "\n",
    "## List of labels\n",
    "index = [0 for i in range (0, len(dictOfLabels))]\n",
    "\n",
    "## Putting the label in the right order\n",
    "for label, i in  dictOfLabels.items():\n",
    "    index[i] = label\n",
    "\n",
    "    \n",
    "def confusion_matrix(mat, qty, pred=None, labels=None, index = index, write_results = False, name = \"Test\", cuda = True): \n",
    "    size = len(index)\n",
    "    \n",
    "    if(write_results):\n",
    "        \n",
    "        ## Dividing by total number:\n",
    "        for k in range(size):\n",
    "            if(qty[k]!= 0):\n",
    "                mat[k] *= 1/qty[k]\n",
    "                \n",
    "        ## Converting mat into data frame in order to use seaborn:\n",
    "        dataframe = pd.DataFrame(mat, index=index)\n",
    "        sn.set(font_scale=1)\n",
    "\n",
    "        # Creates the heatmap:\n",
    "        fig=plt.figure(figsize=(15, 12), dpi= 400, facecolor='w', edgecolor='k')\n",
    "        svm = sn.heatmap(dataframe, annot=False)\n",
    "\n",
    "        # Saves the figure than plots it:\n",
    "        figure = svm.get_figure()\n",
    "        figure.savefig('Images/Confusion_Matrices/Conf_Mat_' + name +'.png', dpi=400)\n",
    "        \n",
    "        del figure\n",
    "        #plt.show()\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        if(pred is None or labels is None):\n",
    "            print(\"Error, inputs can't be None if not in write results mode.\")\n",
    "            return -1\n",
    "\n",
    "        if(mat is None):\n",
    "            #print(\"Initialize confusion matrix\")\n",
    "            mat = np.zeros([size,size])\n",
    "        \n",
    "        if(qty is None):\n",
    "            qty = [0]*size\n",
    "        \n",
    "        if cuda and (not pred.is_cuda or not labels.is_cuda):\n",
    "            pred   = pred.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "        \n",
    "        \n",
    "        for k in range(labels.size(0)): # ground truth first (row) and then prediction (col)\n",
    "         # print(\"Here : \" +str(labels[k].item()) + \" ; \" + str(predicted[k].item()))\n",
    "            mat[labels[k].item(),pred[k].item()] +=1\n",
    "            qty[labels[k].item()]                +=1\n",
    "            \n",
    "        \n",
    "            \n",
    "    return mat, qty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup Augmentation:\n",
    "\n",
    "Credit to Lionel, see original file [here](https://gitlab.tech.orange/lionel.delphinpoulat/dcase2018_task5/-/blob/master/datagenerator.py).<br>\n",
    "Also, this repos helped, see [here](https://github.com/hysts/pytorch_mixup/blob/master/utils.py).<br>\n",
    "To convert into one_hot encoded we use `tensor.scatter_(dim, index, src)`. Its documentation is available [here](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_).<br>\n",
    "\n",
    "    Brief description :\n",
    "> Writes all values from the tensor `src` into `self` at the indices specified in the `index` tensor. For each value in `src`, its output index is specified by its index in `src` for `dimension != dim` and by the corresponding value in `index` for `dimension = dim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(label, n_classes):\n",
    "    return torch.zeros(label.size(0), n_classes).scatter_(\n",
    "        1, label.view(-1, 1), 1)\n",
    "\n",
    "def mixup(data, targets, beta_coef, n_classes, sameClasses = False, debug = False):\n",
    "    if(data.size(0) != targets.size(0)):\n",
    "        print(\"The amount of data and labels are not the same !\")\n",
    "        return -1\n",
    "    \n",
    "    if(sameClasses):\n",
    "        indices_by_labels = {}\n",
    "        \n",
    "        for i, el in enumerate(targets):\n",
    "            ## Gets the value in the tensor:\n",
    "            el = el.item()\n",
    "            \n",
    "            if indices_by_labels.get(el) is None:\n",
    "                indices_by_labels[el] = [i]\n",
    "            else:\n",
    "                l = indices_by_labels[el]\n",
    "                l.append(i)\n",
    "                indices_by_labels[el] = l\n",
    "                        \n",
    "        indices = torch.zeros(targets.size(0), dtype = torch.long)\n",
    "        \n",
    "        for key in indices_by_labels.keys():\n",
    "            \n",
    "            initial_ids = np.array(indices_by_labels[key])\n",
    "            \n",
    "            perm        = np.random.permutation(initial_ids.size)\n",
    "            \n",
    "            new_ids     = initial_ids[perm]\n",
    "            \n",
    "            indices[torch.from_numpy(initial_ids)] = torch.from_numpy(new_ids)\n",
    "            \n",
    "        #print(targets == targets[indices])\n",
    "        \n",
    "    else:\n",
    "        # Creates a random permutation for the data:\n",
    "        indices = torch.randperm(data.size(0))\n",
    "\n",
    "        \n",
    "    # Creates mixed up data:\n",
    "    data_mix    = data[indices]\n",
    "    targets_mix = targets[indices]\n",
    "\n",
    "    # Converts labels into one_hot encoded labels:\n",
    "    targets     = onehot(targets, n_classes)    \n",
    "    targets_mix = onehot(targets_mix, n_classes)\n",
    "    \n",
    "    # draws the mixup coefficient\n",
    "    mixup_var = torch.FloatTensor(np.random.beta(beta_coef, beta_coef, data.size(0)))\n",
    "    \n",
    "    # Computes the percentage of data that are affected by the mixup:\n",
    "    mixup_percentage = np.array([i for i in range (data.size(0))]) != np.array([el.item() for el in indices])\n",
    "    \n",
    "    for i, el in enumerate(mixup_var):\n",
    "        mixup_percentage[i] = (mixup_percentage[i] and (el < 0.9999))\n",
    "\n",
    "    mixup_percentage = sum(mixup_percentage)/data.size(0)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"mix_var shape %s\" % str(mixup_var.shape))\n",
    "        print(\"X shape %s\" % str(data.shape))\n",
    "        print(\"labels %s\" % str(targets))\n",
    "        print(\"mixup vars :\", mixup_var)\n",
    "        print(\"Indices :\", indices)\n",
    "        \n",
    "    # applies mixup to both input data and one-hot encoded labels\n",
    "    X = torch.rand(data.shape, dtype = torch.float)\n",
    "    \n",
    "    for i in range (data.size(0)):\n",
    "        X[i] = data[i] * mixup_var[i] + data_mix[i] * (1. - mixup_var[i])\n",
    "        \n",
    "    y = torch.rand((data.size(0), n_classes), dtype = torch.float)\n",
    "    \n",
    "    for i in range (targets.size(0)):    \n",
    "        y[i] = (targets[i] * mixup_var[i] + targets_mix[i] * (1. - mixup_var[i]))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"mix label shape %s\" % str(y.shape))\n",
    "        print(\"%s\" % str(y[0]))\n",
    "    \n",
    "    return X, y, mixup_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beta density plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "a, b = 0.4, 0.4\n",
    "mean, var, skew, kurt = beta.stats(a, b, moments='mvsk')\n",
    "\n",
    "x = np.linspace(beta.ppf(0.00001, a, b),\n",
    "                beta.ppf(0.99999, a, b), 100)\n",
    "\n",
    "ax.plot(x, beta.pdf(x, a, b),\n",
    "       'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefining cost function for one hot encoded labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing new cost function:\n",
    "cost_onehot = NLLL_OneHot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping:\n",
    "\n",
    "For a **theoretical perspective**, please refer to <cite>Goodfellow, Ian. Deep Learning. Cambridge, Massachusetts, The MIT Press, Publication Date</cite> chapter 7, paragraph 8, page 240, algorithm $7.1$.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Batch_dev is the number of test tensors that are stored at once\n",
    "\"\"\"\n",
    "def accuracy(net, test_loader, criterion, \n",
    "             ## SincNet Params\n",
    "             Batch_dev, wlen, wshift,\n",
    "             ## Confusion_Matrix param:\n",
    "             matrix_name, compute_matrix = False,\n",
    "             cuda=True):\n",
    "    \n",
    "    ## Modifs pour SincNet\n",
    "    net.eval()\n",
    "    \n",
    "\n",
    "    loss_sum=0\n",
    "    err_sum=0\n",
    "    err_sum_snt=0\n",
    "    ## End\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Initializes confusion matrix and quantity to None:\n",
    "        mat = None\n",
    "        qty = None\n",
    "        \n",
    "        ## Initialisation of storing units for testing:\n",
    "        stored_outs   = 0\n",
    "        stored_labels = 0\n",
    "        stored_idx    = 0\n",
    "            \n",
    "        \n",
    "        ## For SincNet, information in testloader is raw and can be of various lengths!\n",
    "        for data in test_loader:\n",
    "            ## Stores data from test_loader:\n",
    "            audios, labels, file_ids = data\n",
    "            \n",
    "            ## Switches to cuda:\n",
    "            if cuda:\n",
    "                audios = audios.type(torch.cuda.FloatTensor)\n",
    "                labels = labels.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            \n",
    "            ## <!> Splits the data by file: time_complexity = O(batch_size) and space_complexity = O(Number_Of_Files)\n",
    "            section  = []\n",
    "            ids_list = []\n",
    "            current_idx = file_ids[0].item()\n",
    "            ids_list.append(current_idx)\n",
    "            for i, el in enumerate(file_ids):\n",
    "                current_el = el.item()\n",
    "                if current_el != current_idx:\n",
    "                    current_idx = current_el\n",
    "                    ids_list.append(current_idx)\n",
    "                    section.append(i - sum(section))\n",
    "\n",
    "            ## Last section is added:    \n",
    "            section.append(audios.size(0) - sum(section))\n",
    "            #print(section)\n",
    "            #print(ids_list)\n",
    "\n",
    "            ## Algorithm that splits the tensors by file:\n",
    "            X_split = torch.split(audios, section)\n",
    "            y_split = torch.split(labels, section)\n",
    "\n",
    "            assert(len(X_split) == len(y_split))\n",
    "            ## <!> EndSplit <!>\n",
    "\n",
    "            \n",
    "            ## Processes file by file the data:\n",
    "            for i in range(len(X_split)):# nbre_fichier_par_batch= len(X_split)\n",
    "                ## Stores the current id:\n",
    "                current_idx    = ids_list[i]\n",
    "                current_data   = X_split[i] if len(X_split) >= 1 else X_split\n",
    "                current_labels = y_split[i] if len(y_split) >= 1 else y_split\n",
    "\n",
    "                if type(stored_outs) is not torch.Tensor:\n",
    "                    stored_idx    = current_idx\n",
    "                    stored_outs   = net(current_data)\n",
    "                    stored_labels = current_labels\n",
    "\n",
    "                    ## Updates the number of signals\n",
    "                    #nbr_snt      += 1\n",
    "                else:\n",
    "\n",
    "                    if(stored_idx == current_idx):\n",
    "                        stored_outs   = torch.cat([stored_outs, net(current_data)], dim=0)\n",
    "                        stored_labels = torch.cat([stored_labels, current_labels], dim=0)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        #pout = stored_outs\n",
    "\n",
    "                        ## Predicts for every chunk of audio the label and counts how many time it got it correctly\n",
    "                        pred = torch.max(stored_outs,dim=1)[1]\n",
    "                        loss = criterion(stored_outs, stored_labels.long())\n",
    "                        err  = torch.mean((pred!=stored_labels.long()).float())\n",
    "\n",
    "                        ## Updates the confusion matrix:\n",
    "                        if(compute_matrix):\n",
    "                            mat, qty = confusion_matrix(mat, qty, pred=pred, labels=stored_labels, write_results = False, name = \"Pas Important\", cuda = True)\n",
    "\n",
    "                        ## Updates the error that I use here:\n",
    "                        loss_sum=loss_sum+loss.detach()\n",
    "                        err_sum=err_sum+err.detach()\n",
    "\n",
    "                        ## Sum the probability over the columns, then it stores the value and the position of the max. (Lionel's Method)\n",
    "                        [val,best_class]=torch.max(torch.sum(stored_outs,dim=0), 0)\n",
    "                        err_sum_snt=err_sum_snt+(best_class!=stored_labels[0]).float()\n",
    "\n",
    "                        ## Stores new data:\n",
    "                        stored_outs   = net(current_data)\n",
    "                        stored_labels = y_split[i] if len(y_split) >= 1 else y_split\n",
    "                        stored_idx    = current_idx\n",
    "        \n",
    "        ## Last File is not processed by the algorithm above...\n",
    "        if(stored_outs.size(0) != 0):\n",
    "            ## Predicts for every chunk of audio the label and counts how many time it got it correctly\n",
    "            pred = torch.max(stored_outs,dim=1)[1]\n",
    "            loss = criterion(stored_outs, stored_labels.long())\n",
    "            err  = torch.mean((pred!=stored_labels.long()).float())\n",
    "\n",
    "            ## Updates the confusion matrix:\n",
    "            if(compute_matrix):\n",
    "                mat, qty = confusion_matrix(mat, qty, pred=pred, labels=stored_labels, write_results = False, name = \"Pas Important\", cuda = True)\n",
    "\n",
    "            ## Updates the error that I use here:\n",
    "            loss_sum=loss_sum+loss.detach()\n",
    "            err_sum=err_sum+err.detach()\n",
    "\n",
    "            ## Sum the probability over the columns, then it stores the value and the position of the max. (Lionel's Method)\n",
    "            [val,best_class]=torch.max(torch.sum(stored_outs,dim=0), 0)\n",
    "            err_sum_snt=err_sum_snt+(best_class!=stored_labels[0]).float()\n",
    "        \n",
    "        ## mean Error of best class:\n",
    "        err_tot_dev_snt=err_sum_snt/snt_te\n",
    "        \n",
    "        ## mean Loss:\n",
    "        loss_tot_dev=loss_sum/snt_te\n",
    "        \n",
    "        ## mean Error on each window:\n",
    "        err_tot_dev=err_sum/snt_te\n",
    "\n",
    "        ## Plots and saves the confusion matrix:\n",
    "        if(compute_matrix):\n",
    "            mat = confusion_matrix(mat, qty, write_results = True, name = matrix_name, cuda = True)\n",
    "            \n",
    "            \n",
    "    net.train()\n",
    "\n",
    "    return (err_tot_dev_snt, loss_tot_dev, err_tot_dev)\n",
    "\n",
    "def train(net, optimizer, train_loader, valid_loader, criterion, criterion_onehot,\n",
    "          ## SincNet variables:\n",
    "          wlen,\n",
    "          wshift,\n",
    "          n_classes,\n",
    "          ## File variables:\n",
    "          output_folder,\n",
    "          fname,\n",
    "          Models_file_extension,\n",
    "          ## Hyper param:\n",
    "          n_epoch = 5,\n",
    "          patience = 4,\n",
    "          Batch_dev = 32,#Number of batches for testing set\n",
    "          train_acc_period = 100,\n",
    "          test_acc_period = 5,\n",
    "          ## For mixup:\n",
    "          beta_coef = 0.5,\n",
    "          use_mixup = False,\n",
    "          same_classes = False,\n",
    "          ## If a Net was loaded:\n",
    "          starting_epoch = 0,\n",
    "          ## If user wishes to plot grad:\n",
    "          plotGrad = False,\n",
    "          ## If user wishes to use a scheduler:\n",
    "          use_scheduler = False,\n",
    "          scheduler = None,\n",
    "          ## If user wishes to save and compute confusion matrix:\n",
    "          compute_matrix = False,\n",
    "          ## Indicates if the network that is trained is SincNet\n",
    "          is_SincNet = False,\n",
    "          ## Is Cuda activated?\n",
    "          cuda=True):\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    ## Initialization:\n",
    "    min_loss = float(\"inf\")\n",
    "    \n",
    "    ## best_epoch_number is a var that stores the number of epoch required for best performance:\n",
    "    best_epoch_number = 0\n",
    "    \n",
    "    ## p is a counter for how many accuracy checks we made without any improvement on validation loss:\n",
    "    p=0\n",
    "    \n",
    "    ## Declaring to the user that training has begun\n",
    "    print(\"Trainining begun with a patience of {} accuracy periods\".format(patience), end=\"\")\n",
    "    if(use_mixup):\n",
    "        string = \"\"\n",
    "        if(same_classes):\n",
    "            string = \"Same Class \"\n",
    "        print(\" and using {1}mixup with a Beta({0}, {0}) distribution.\".format(beta_coef, string))\n",
    "    else:\n",
    "        print(\".\")\n",
    "    if use_scheduler:\n",
    "        print(\"Training is optimized with a scheduler.\")\n",
    "    print(\"Total number of classes is equal to : {}\".format(n_classes))\n",
    "    \n",
    "    ## Continues training beyond n_epoch if algorithm did not converge:\n",
    "    while(p < patience):\n",
    "        \n",
    "        for epoch in tqdm.tqdm(range(starting_epoch + 1, n_epoch + starting_epoch + 1)):  # loop over the dataset multiple times\n",
    "\n",
    "            ## Stops the training if we exceeded its patience!\n",
    "            if(p >= patience):\n",
    "                break\n",
    "\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            running_mixup_percentage = 0.0\n",
    "\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "                # Getting Mixed up data if required by user:\n",
    "                if(use_mixup):\n",
    "                    inputs, labels, mixup_states     = data\n",
    "                    mixup_percentage                 = mixup_states.sum().item() / inputs.size(0)\n",
    "                    running_mixup_percentage         = 0.33*mixup_percentage + 0.66*running_mixup_percentage\n",
    "                else:\n",
    "                    # gets the regular inputs\n",
    "                    inputs, labels = data\n",
    "                    \n",
    "                    \n",
    "\n",
    "                if cuda:\n",
    "                    inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "                    labels = labels.type(torch.cuda.LongTensor)\n",
    "\n",
    "                # print(inputs.shape)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                ## Loss evaluation:\n",
    "                    # We use custom made function if there is mixup envolved\n",
    "                    # Else, we use regular criterion from pytorch\n",
    "                if(use_mixup):\n",
    "                    loss = criterion_onehot(outputs, labels.long())\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels.long())\n",
    "                    \n",
    "                    \n",
    "                loss.backward()\n",
    "\n",
    "                ## Plotting the grad for frequencies and second layer 1Dconv:\n",
    "                if(plotGrad):\n",
    "                    plot_grad_flow(net.named_parameters())   \n",
    "                    #plot_grad_flow_simple(net.named_parameters())\n",
    "\n",
    "                optimizer.step()\n",
    "                    \n",
    "                ## If we used mixup, we need to convert back labels to og format.\n",
    "                if(use_mixup):\n",
    "                    labels = torch.max(labels, dim = 1)[1]\n",
    "\n",
    "                running_loss = 0.33*loss.detach() + 0.66*running_loss\n",
    "                predicted = torch.max(outputs.data, dim = 1)[1]\n",
    "\n",
    "                ## @correct is the percentage of correct answers by the Net.\n",
    "                correct = (predicted == labels).sum().item()/labels.size(0)\n",
    "                running_acc = 0.33*correct + 0.66*running_acc\n",
    "\n",
    "                # prints statistics during epoch!\n",
    "                if i % train_acc_period == train_acc_period-1:\n",
    "                    print(\"Training set : \")\n",
    "                    print('[%d, %5d] running loss: %.3f' %(epoch, i + 1, running_loss))\n",
    "                    print('[%d, %5d] running acc: %.3f' %(epoch, i + 1, running_acc))\n",
    "                    \n",
    "                    if use_mixup:\n",
    "                        print('[%d, %5d] running mixup percentage: %.3f' %(epoch, i + 1, running_mixup_percentage))\n",
    "\n",
    "\n",
    "\n",
    "            ## Validation loop part:\n",
    "            if epoch % test_acc_period == 0:\n",
    "                best_class_error, cur_loss, window_error = accuracy(net, valid_loader, criterion, \n",
    "                                                                    Batch_dev, wlen, wshift,\n",
    "                                                                    matrix_name = fname, compute_matrix = compute_matrix,\n",
    "                                                                    cuda=cuda)\n",
    "                \n",
    "                \n",
    "                \n",
    "                ## If user wishes to use a scheduler:\n",
    "                if(use_scheduler):\n",
    "                    scheduler.step(cur_loss)\n",
    "\n",
    "\n",
    "                ## Writing the results in the specified file:\n",
    "                with open(output_folder+\"/\" + fname + \".res\", \"a\") as res_file:\n",
    "                    res_file.write(\"epoch %i, running_loss_tr=%f running_acc_tr=%f best_class_acc_te=%f loss_te=%f window_acc_te=%f \\n\" % \n",
    "                                                                                                 (epoch,\n",
    "                                                                                                 running_loss,\n",
    "                                                                                                 running_acc,\n",
    "                                                                                                 1-best_class_error,\n",
    "                                                                                                 cur_loss,\n",
    "                                                                                                 1-window_error))   \n",
    "\n",
    "                print(\"\\n\")\n",
    "                print(\"Validation set : \")\n",
    "                print('[%d] test loss: %.3f'       %(epoch, cur_loss))\n",
    "                print('[%d] window acc: %.3f'      %(epoch, 1-window_error))\n",
    "                print('[%d] best class acc: %.3f'  %(epoch, 1-best_class_error))\n",
    "\n",
    "\n",
    "                if(cur_loss < min_loss):\n",
    "                    ## Saves the new loss:\n",
    "                    min_loss = cur_loss\n",
    "\n",
    "                    ## Saves the parameters if they are better:\n",
    "                    # SincNet saving method:\n",
    "                    if is_SincNet:\n",
    "                        torch.save(net.CNN_net.state_dict(), output_folder + '/' + fname + \"_CNN\" + Models_file_extension)\n",
    "                        torch.save(net.DNN1_net.state_dict(), output_folder+ '/' + fname + \"_DNN1\" + Models_file_extension)\n",
    "                        torch.save(net.DNN2_net.state_dict(), output_folder+ '/' + fname + \"_DNN2\" + Models_file_extension)\n",
    "                    \n",
    "                    # Regular save:\n",
    "                    torch.save(net.state_dict(), output_folder+ '/' + fname + \"_Main_net\" + Models_file_extension)\n",
    "\n",
    "                    ## Resets the patience, we found a better net.\n",
    "                    p = 0\n",
    "\n",
    "                    ## Stores the best number of epoch:\n",
    "                    best_epoch_number = epoch\n",
    "\n",
    "                else:\n",
    "                    p +=1\n",
    "        \n",
    "        ## Inside While scope:\n",
    "        starting_epoch += n_epoch#Here we go again...\n",
    "\n",
    "\n",
    "      \n",
    "    print('Finished Training, the best number of epoch was {}.'.format(best_epoch_number))\n",
    "    \n",
    "    # If user wants to plot grad: \n",
    "    if(plotGrad):\n",
    "        ## Saves figure:\n",
    "        plt.savefig(\"Images/\" + fname + \"_GradFlow.png\", format = 'png')\n",
    "        \n",
    "        ## Then shows the figure:\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading previously trained model if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadPrevModel(model_file_path, Models_file_extension, Load, evalMode = False, inSameFile = True, at_epoch = N_epochs):\n",
    "    if(Load == False):\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    ## Setting the parameters of the previously defined networks \n",
    "    global Main_net, CNN_net, DNN1_net, DNN2_net\n",
    "    \n",
    "    \n",
    "    if(inSameFile):\n",
    "        ## Loading the pretrained setup file\n",
    "        pretrainedSetup = torch.load(model_file_path + Models_file_extension)\n",
    "        #print(pretrainedSetup['CNN_model_par'])\n",
    "        \n",
    "        ## Loading net parameters one by one:\n",
    "        CNN_net.load_state_dict(pretrainedSetup['CNN_model_par'])\n",
    "        if(evalMode):CNN_net.eval()\n",
    "\n",
    "        DNN1_net.load_state_dict(pretrainedSetup['DNN1_model_par'])\n",
    "        if(evalMode):DNN1_net.eval()\n",
    "\n",
    "        DNN2_net.load_state_dict(pretrainedSetup['DNN2_model_par'])\n",
    "        if(evalMode):DNN2_net.eval()\n",
    "                    \n",
    "    else:\n",
    "        ## Loading all the pretrained setup file\n",
    "        \n",
    "        pretrainedSetup_CNN  = torch.load(model_file_path + \"_CNN\" + Models_file_extension)\n",
    "        pretrainedSetup_DNN1 = torch.load(model_file_path + \"_DNN1\" + Models_file_extension)\n",
    "        pretrainedSetup_DNN2 = torch.load(model_file_path + \"_DNN2\" + Models_file_extension)\n",
    "        \n",
    "        ## Loading net parameters one by one:\n",
    "        CNN_net.load_state_dict(pretrainedSetup_CNN)\n",
    "        if(evalMode):CNN_net.eval()\n",
    "\n",
    "        DNN1_net.load_state_dict(pretrainedSetup_DNN1)\n",
    "        if(evalMode):DNN1_net.eval()\n",
    "\n",
    "        DNN2_net.load_state_dict(pretrainedSetup_DNN2)\n",
    "        if(evalMode):DNN2_net.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Putting all the nets into Main_net:\n",
    "    Main_net = Main_net = MainNet(CNN_net, DNN1_net, DNN2_net)\n",
    "    if(evalMode):Main_net.eval()\n",
    "\n",
    "    \n",
    "    #print(CNN_net.state_dict()['conv.0.low_hz_'][0])\n",
    "    \n",
    "    print(\"Models from \" + model_file_path + \" were loaded successfully!\")\n",
    "    \n",
    "    return at_epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters that needs to change each execution:\n",
    "Training_model_file   = output_folder.split(\"/\")[-2] if output_folder.split(\"/\")[-1]==\"\" else output_folder.split(\"/\")[-1]\n",
    "Training_model_file  += \"_Notebook\"\n",
    "Models_file_extension = \".pkl\" if pt_file == 'none' else pt_file.split(\".\")[1]\n",
    "previous_model_path   = output_folder+ '/' + Training_model_file if pt_file == 'none' else pt_file.split(\".\")[0]\n",
    "Load_previous_model   = False if pt_file == 'none' else True\n",
    "at_epoch              = 0\n",
    "inTheSameFile         = False\n",
    "plotGrad              = False\n",
    "n_classes             = class_lay[-1]#41 for SincNet\n",
    "same_classes          = same_classes\n",
    "compute_matrix        = False\n",
    "is_SincNet            = True\n",
    "\n",
    "\n",
    "## are in cfg:\n",
    "#beta_coef=0.4\n",
    "#use_mixup\n",
    "#N_eval_epoch = 1\n",
    "#same_classes = True\n",
    "#use_scheduler         = True\n",
    "\n",
    "\n",
    "## Loading previously trained model if needed:\n",
    "previous_epoch = LoadPrevModel(previous_model_path, \n",
    "                               Models_file_extension, \n",
    "                               Load= Load_previous_model, \n",
    "                               inSameFile = inTheSameFile,\n",
    "                               at_epoch = at_epoch,\n",
    "                               evalMode = True)\n",
    "\n",
    "\n",
    "## Training parameters available in the SincNet_TIMIT.cfg file section [optimization]:\n",
    "# batch_size\n",
    "# N_epochs     = 1500\n",
    "# N_batches    = 800\n",
    "# N_eval_epoch = 8\n",
    "\n",
    "## Overwriting N_epochs just bcz flemme:\n",
    "#N_epochs = 58\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training occurs below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainining begun with a patience of 7 accuracy periods.\n",
      "Training is optimized with a scheduler.\n",
      "Total number of classes is equal to : 41\n",
      "Training set : \n",
      "[1,   100] running loss: 2.913\n",
      "[1,   100] running acc: 0.151\n",
      "Training set : \n",
      "[1,   200] running loss: 2.821\n",
      "[1,   200] running acc: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:28<46:31, 28.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : \n",
      "[2,   100] running loss: 2.832\n",
      "[2,   100] running acc: 0.211\n",
      "Training set : \n",
      "[2,   200] running loss: 2.511\n",
      "[2,   200] running acc: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 2/100 [00:56<46:04, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : \n",
      "[3,   100] running loss: 2.773\n",
      "[3,   100] running acc: 0.190\n",
      "Training set : \n",
      "[3,   200] running loss: 2.518\n",
      "[3,   200] running acc: 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 3/100 [01:24<45:39, 28.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : \n",
      "[4,   100] running loss: 2.601\n",
      "[4,   100] running acc: 0.213\n",
      "Training set : \n",
      "[4,   200] running loss: 2.570\n",
      "[4,   200] running acc: 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 4/100 [01:53<45:17, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : \n",
      "[5,   100] running loss: 2.379\n",
      "[5,   100] running acc: 0.250\n",
      "Training set : \n",
      "[5,   200] running loss: 2.335\n",
      "[5,   200] running acc: 0.293\n",
      "\n",
      "\n",
      "Validation set : \n",
      "[5] test loss: 2.433\n",
      "[5] window acc: 0.314\n",
      "[5] best class acc: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 5/100 [03:48<1:25:55, 54.27s/it]"
     ]
    }
   ],
   "source": [
    "train(Main_net, optimizers, train_loader, valid_loader, cost, cost_onehot,\n",
    "          ## SincNet variables:\n",
    "          wlen,\n",
    "          wshift,\n",
    "          n_classes,\n",
    "          ## File variables:\n",
    "          output_folder,\n",
    "          Training_model_file,\n",
    "          Models_file_extension,\n",
    "          ## Hyper param:\n",
    "          n_epoch = N_epochs,\n",
    "          patience = patience,\n",
    "          Batch_dev = Batch_dev,#Number of batches for testing set\n",
    "          train_acc_period = train_acc_period,\n",
    "          test_acc_period = N_eval_epoch,\n",
    "          ## For Mixup\n",
    "          beta_coef = beta_coef,\n",
    "          use_mixup = use_mixup,\n",
    "          same_classes = same_classes,\n",
    "          ## Loaded model params:\n",
    "          starting_epoch = previous_epoch,\n",
    "          ## Tracking gradient\n",
    "          plotGrad = plotGrad,\n",
    "          ## If user wishes to use scheduler:\n",
    "          use_scheduler = use_scheduler,\n",
    "          scheduler = schedulers,\n",
    "          ## If user wishes to save and compute confusion matrix:\n",
    "          compute_matrix = compute_matrix,\n",
    "          ## Indicates if the network that is trained is SincNet\n",
    "          is_SincNet = is_SincNet,\n",
    "          cuda=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magical Line of code that empties the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexes:\n",
    "\n",
    "> This part is for unused algorithms that were at some point useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brut force method:\n",
    " We load everything on RAM because we can..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_on_Ram(data_folder,wav_lst,N_snt,lab_dict, fact_amp, wlen):\n",
    "    \n",
    "    # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch = []\n",
    "    lab_batch = []\n",
    "    \n",
    "    \n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,N_snt)\n",
    "    \n",
    "    for i in range(N_snt):\n",
    "        \n",
    "        ## Small Hotfix on windows, we do not put the / before the path.\n",
    "        [signal, fs] = librosa.core.load(data_folder + wav_lst[i], sr=None)\n",
    "        \n",
    "        ## Get signal length:\n",
    "        snt_len = len(signal)\n",
    "        \n",
    "        if(snt_len-wlen < 0): \n",
    "            raise Exception(\"error len is too small {0} < {1}\".format(snt_len, wlen))\n",
    "            print(\"error\")\n",
    "            break\n",
    "            \n",
    "\n",
    "        channels = len(signal.shape)\n",
    "        \n",
    "        ## Their conversion stereo Mono is not taking the mean, like I did, \n",
    "        ## but rather taking the first columns\n",
    "        if channels == 2:\n",
    "            print('WARNING: stereo to mono: '+data_folder+wav_lst[i])\n",
    "            signal = signal[:,0]\n",
    "            \n",
    "        snt_beg= 0 if snt_len-wlen-1 in (0, -1) else np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        snt_end=snt_beg+wlen\n",
    "\n",
    "        \n",
    "        ## Signal is stored and randomly amplified\n",
    "        #Time complexity of copy operation is O(fs* wlen/1000)\n",
    "        #https://wiki.python.org/moin/TimeComplexity\n",
    "        singal = [el * rand_amp_arr[i] for el in signal.tolist()[snt_beg: snt_end]]\n",
    "        \n",
    "        sig_batch.append(signal.tolist()[snt_beg: snt_end])\n",
    "        lab_batch.append(lab_dict[wav_lst[i]])\n",
    "        if(i<5):print(len(sig_batch[i]), lab_batch)\n",
    "\n",
    "        \n",
    "    \n",
    "    tensor_x = torch.FloatTensor(sig_batch) # transform to torch tensor\n",
    "    del sig_batch\n",
    "    tensor_y = torch.FloatTensor(lab_batch)\n",
    "    del lab_batch\n",
    "    \n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y)\n",
    "    \n",
    "    return dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Loading all the training dataset on RAM, beceause we can with 64 GB of RAM!\n",
    "train_dataset = load_dataset_on_Ram(data_folder, wav_lst_tr, 5,#len(wav_lst_tr),\n",
    "                                    lab_dict, 0.2, wlen)\n",
    "test_dataset  = load_dataset_on_Ram(data_folder, wav_lst_te, 5,#len(wav_lst_te),\n",
    "                                    lab_dict, 0.2, wlen)\n",
    "#print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defines the loaders:\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "valid_loader  = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm That was used for new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 20]\n",
      "[0, 1]\n",
      "(tensor([[-0.1218, -0.1462, -0.1257,  ..., -0.2727, -0.3080, -0.3364],\n",
      "        [ 0.1029,  0.0696,  0.0426,  ...,  0.1946,  0.1648,  0.1294],\n",
      "        [-0.2260, -0.2151, -0.1955,  ..., -0.1181, -0.1349, -0.1238],\n",
      "        ...,\n",
      "        [-0.1667, -0.2136, -0.2070,  ...,  0.0901,  0.0955,  0.0840],\n",
      "        [-0.3293, -0.3412, -0.3814,  ...,  0.3096,  0.3188,  0.3355],\n",
      "        [ 0.0308, -0.0971, -0.1494,  ..., -0.1729, -0.2203, -0.2404]]), tensor([[-3.1162e-05, -3.3168e-07,  3.2861e-05,  ...,  3.2443e-02,\n",
      "          1.3248e-02,  1.8848e-03],\n",
      "        [ 1.4278e-02, -3.9172e-03, -4.4962e-02,  ..., -1.2917e-01,\n",
      "         -1.3032e-01, -1.3979e-01],\n",
      "        [-1.6374e-02,  2.6467e-02,  1.7332e-02,  ...,  1.6865e-01,\n",
      "          1.7071e-01,  1.6238e-01],\n",
      "        ...,\n",
      "        [ 3.9253e-02,  2.0674e-02,  3.5646e-02,  ...,  1.5996e-01,\n",
      "          1.8126e-01,  1.8925e-01],\n",
      "        [ 2.0677e-02, -1.7662e-01, -1.8921e-01,  ..., -1.0287e-02,\n",
      "         -6.2360e-02, -8.5594e-02],\n",
      "        [ 1.7213e-01,  2.0488e-01,  1.3005e-01,  ..., -1.9878e-01,\n",
      "         -2.0655e-01, -1.5247e-01]]))\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[32]\n",
      "[1]\n",
      "(tensor([[-0.1143, -0.1088, -0.1286,  ...,  0.0267, -0.0971, -0.0948],\n",
      "        [-0.1218, -0.2342, -0.2587,  ..., -0.0743, -0.1285, -0.2882],\n",
      "        [-0.2616, -0.2390, -0.2728,  ..., -0.1058, -0.0435,  0.0032],\n",
      "        ...,\n",
      "        [-0.0030, -0.0319, -0.0798,  ..., -0.2780, -0.2221, -0.1120],\n",
      "        [ 0.0409,  0.0724,  0.0578,  ..., -0.3602, -0.4073, -0.3991],\n",
      "        [ 0.1996,  0.1068, -0.0166,  ...,  0.0926,  0.1418,  0.1642]]),)\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[32]\n",
      "[1]\n",
      "(tensor([[ 0.0978,  0.0288, -0.0022,  ...,  0.6494,  0.6263,  0.7159],\n",
      "        [ 0.0701,  0.0526,  0.0378,  ...,  0.2711,  0.2876,  0.3016],\n",
      "        [ 0.0737,  0.0490, -0.0085,  ...,  0.0450,  0.0523,  0.0634],\n",
      "        ...,\n",
      "        [-0.3695, -0.2993, -0.2965,  ...,  0.3093,  0.3292,  0.3262],\n",
      "        [-0.0131,  0.0169,  0.0843,  ...,  0.1225,  0.0741,  0.0566],\n",
      "        [ 0.1825,  0.0711, -0.0238,  ..., -0.0938,  0.0211, -0.1960]]),)\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[32]\n",
      "[1]\n",
      "(tensor([[ 0.3090,  0.2795,  0.2204,  ...,  0.0996,  0.0091, -0.0308],\n",
      "        [ 0.1776,  0.1952,  0.2189,  ..., -0.0039, -0.0222, -0.0463],\n",
      "        [ 0.1341,  0.1312,  0.1309,  ...,  0.4931,  0.5065, -0.0594],\n",
      "        ...,\n",
      "        [-0.2349, -0.2190, -0.1962,  ..., -0.1642, -0.1599, -0.1553],\n",
      "        [ 0.0043,  0.0054,  0.0108,  ..., -0.2487, -0.2361, -0.2230],\n",
      "        [-0.0462, -0.0477, -0.0459,  ..., -0.0091, -0.1099, -0.1772]]),)\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[32]\n",
      "[1]\n",
      "(tensor([[ 0.2095,  0.2042,  0.1860,  ...,  0.0205,  0.0203,  0.0198],\n",
      "        [-0.0578, -0.0593, -0.0610,  ...,  0.0478,  0.0529,  0.0498],\n",
      "        [-0.1665, -0.1138, -0.0524,  ...,  0.0337,  0.0566,  0.0666],\n",
      "        ...,\n",
      "        [-0.0679, -0.0705, -0.0679,  ...,  0.0388,  0.0998,  0.1356],\n",
      "        [ 0.0944,  0.1855,  0.1117,  ..., -0.0832,  0.3058,  0.2752],\n",
      "        [-0.5426, -0.5444, -0.3812,  ..., -0.3011, -0.4031, -0.4820]]),)\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[32]\n",
      "[1]\n",
      "(tensor([[-0.1191, -0.1407, -0.1249,  ..., -0.0461, -0.0467, -0.0449],\n",
      "        [ 0.2906,  0.2849,  0.2880,  ...,  0.0481,  0.0717,  0.0600],\n",
      "        [-0.2145, -0.2601, -0.2697,  ..., -0.5081, -0.4901, -0.5101],\n",
      "        ...,\n",
      "        [-0.0962, -0.0744, -0.0616,  ..., -0.3556, -0.4488, -0.3373],\n",
      "        [ 0.0899, -0.0188, -0.0112,  ...,  0.2314,  0.1523,  0.0741],\n",
      "        [ 0.3777,  0.3999,  0.4160,  ..., -0.1834, -0.2083, -0.2312]]),)\n",
      "1\n",
      "tensor(3.7136, device='cuda:1') tensor(1., device='cuda:1') tensor(1., device='cuda:1')\n",
      "20\n",
      "[10, 22]\n",
      "[1, 2]\n",
      "(tensor([[ 0.1292,  0.1465,  0.1665,  ..., -0.1037,  0.0573, -0.0131],\n",
      "        [-0.1105,  0.1236,  0.2160,  ..., -0.2141, -0.2026, -0.1838],\n",
      "        [ 0.3307,  0.3724,  0.5014,  ...,  0.0659,  0.0830,  0.1031],\n",
      "        ...,\n",
      "        [-0.1517, -0.1435, -0.3491,  ..., -0.2282, -0.2745, -0.2528],\n",
      "        [ 0.0347,  0.0409,  0.0718,  ..., -0.2679, -0.2552, -0.2634],\n",
      "        [-0.2447, -0.2600, -0.2765,  ...,  0.1928,  0.1884,  0.1932]]), tensor([[-0.0017, -0.0202, -0.0331,  ...,  0.0410,  0.0696,  0.0945],\n",
      "        [-0.0681, -0.0609, -0.0558,  ...,  0.0325,  0.0388,  0.0462],\n",
      "        [ 0.1432,  0.1364,  0.1248,  ...,  0.0861,  0.0985,  0.1080],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0264,  0.0242,  ...,  0.1156,  0.0994,  0.0796],\n",
      "        [ 0.3579,  0.3585,  0.3497,  ...,  0.0842,  0.0882,  0.0889],\n",
      "        [ 0.4232,  0.4275,  0.4213,  ...,  0.0201,  0.0204,  0.0204]]))\n",
      "2\n",
      "tensor(7.4271, device='cuda:1') tensor(1.9632, device='cuda:1') tensor(2., device='cuda:1')\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "criterion = cost\n",
    "\n",
    "## To remove:\n",
    "CNN_net.eval()\n",
    "DNN1_net.eval()\n",
    "DNN2_net.eval()\n",
    "\n",
    "\n",
    "## Initialisation before forloop\n",
    "stored_labels = 0\n",
    "stored_outs   = 0\n",
    "stored_idx    = 0\n",
    "\n",
    "loss_sum    = 0\n",
    "err_sum     = 0\n",
    "err_sum_snt = 0\n",
    "\n",
    "\n",
    "current_idx = 0\n",
    "\n",
    "nbr_snt = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "\n",
    "        if(i >= 7):\n",
    "            break\n",
    "\n",
    "        X, labels, tensor_ids = data\n",
    "\n",
    "        section = []\n",
    "        ids_list = []\n",
    "        current_idx = tensor_ids[0].item()\n",
    "        ids_list.append(current_idx)\n",
    "        for i, el in enumerate(tensor_ids):\n",
    "            current_el = el.item()\n",
    "            if current_el != current_idx:\n",
    "                current_idx = current_el\n",
    "                ids_list.append(current_idx)\n",
    "                section.append(i - sum(section))\n",
    "\n",
    "        ## Last section is added:    \n",
    "        section.append(X.size(0) - sum(section))\n",
    "        print(section)\n",
    "        print(ids_list)\n",
    "\n",
    "        ## Algorithm that splits the tensors by file:\n",
    "        X_split = torch.split(X, section)\n",
    "        y_split = torch.split(labels, section)\n",
    "\n",
    "        assert(len(X_split) == len(y_split))\n",
    "\n",
    "        for i in range(len(X_split)):\n",
    "            ## Stores the current id:\n",
    "            current_idx    = ids_list[i]\n",
    "            current_data   = X_split[i] if len(X_split) >= 1 else X_split\n",
    "            current_labels = y_split[i] if len(y_split) >= 1 else y_split\n",
    "            \n",
    "            ## To delete:\n",
    "            current_data   = current_data.type(torch.cuda.FloatTensor)\n",
    "            current_labels = current_labels.type(torch.cuda.LongTensor)\n",
    "            \n",
    "\n",
    "            if type(stored_outs) is not torch.Tensor:\n",
    "                stored_idx    = current_idx\n",
    "                stored_outs   = DNN2_net(DNN1_net(CNN_net(current_data)))\n",
    "                stored_labels = current_labels\n",
    "\n",
    "                ## Updates the number of signals\n",
    "                nbr_snt      += 1\n",
    "            else:\n",
    "\n",
    "                if(stored_idx == current_idx):\n",
    "                     ## To delete:\n",
    "                    stored_outs   = stored_outs.type(torch.cuda.FloatTensor)\n",
    "                    stored_labels = stored_labels.type(torch.cuda.LongTensor)\n",
    "                    \n",
    "                    \n",
    "                    stored_outs   = torch.cat([stored_outs, DNN2_net(DNN1_net(CNN_net(current_data)))], dim=0)\n",
    "                    stored_labels = torch.cat([stored_labels, current_labels], dim=0)\n",
    "\n",
    "                else:\n",
    "                    ## To delete:\n",
    "                    stored_outs   = stored_outs.type(torch.cuda.FloatTensor)\n",
    "                    stored_labels = stored_labels.type(torch.cuda.LongTensor)\n",
    "                    compute_matrix = False\n",
    "                    ## End to delete--\n",
    "\n",
    "                    #pout = stored_outs\n",
    "\n",
    "                    ## Predicts for every chunk of audio the label and counts how many time it got it correctly\n",
    "                    pred = torch.max(stored_outs,dim=1)[1]\n",
    "                    loss = criterion(stored_outs, stored_labels.long())\n",
    "                    err  = torch.mean((pred!=stored_labels.long()).float())\n",
    "\n",
    "                    ## Updates the confusion matrix:\n",
    "                    if(compute_matrix):\n",
    "                        mat, qty = confusion_matrix(mat, qty, pred=pred, labels=stored_labels, write_results = False, name = \"Pas Important\", cuda = True)\n",
    "\n",
    "                    ## Updates the error that I use here:\n",
    "                    loss_sum=loss_sum+loss.detach()\n",
    "                    err_sum=err_sum+err.detach()\n",
    "\n",
    "                    ## Sum the probability over the columns, then it stores the value and the position of the max. (Lionel's Method)\n",
    "                    [val,best_class]=torch.max(torch.sum(stored_outs,dim=0), 0)\n",
    "                    err_sum_snt=err_sum_snt+(best_class!=stored_labels[0]).float()\n",
    "\n",
    "                    ## Stores new data:\n",
    "                    stored_outs   = DNN2_net(DNN1_net(CNN_net(current_data)))\n",
    "                    stored_labels = y_split[i] if len(y_split) >= 1 else y_split\n",
    "                    stored_idx    = current_idx\n",
    "                    nbr_snt      += 1\n",
    "\n",
    "\n",
    "\n",
    "        print(X_split)\n",
    "        print(current_idx)\n",
    "        print(loss_sum, err_sum, err_sum_snt)\n",
    "        print(stored_data.size(0))\n",
    "    nbr_snt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First method used to create Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Objective: (will change, I am thinking of putting it with preprocessing functions)\n",
    "    We want to convert the audio files at @data_folder that are in @wav_lst into tensors and then store them on the Hard disk.\n",
    "    It will save us some RAM, but also will allow us to have a dataset of tensors with != shapes.\n",
    "\n",
    "Args:\n",
    "    @lab_dict     is a dictionary that contains the true labels of the audio files, keys are the file names and values are the label.\n",
    "    @data_folder  is the path to the folder containing the audio files\n",
    "    @wav_lst      is the list of audio files to transform into tensors\n",
    "    @N_snt        is the number of files to transform\n",
    "    @path_to_save is the path where the tensors need to be written at\n",
    "\"\"\"\n",
    "\n",
    "## Maybe move it to preprocessing ? Lionel's aproval.\n",
    "def create_audio_tensors(lab_dict, data_folder, wav_lst, N_snt, path_to_save):\n",
    "    \n",
    "    tensors_lst = []\n",
    "    \n",
    "    for i in range(N_snt):\n",
    "        \n",
    "        current_file_name = wav_lst[i]\n",
    "        \n",
    "        [signal, fs] = librosa.core.load(data_folder + current_file_name, sr=None)\n",
    "        \n",
    "        temp_t = torch.tensor(signal).float()\n",
    "        \n",
    "        new_name = current_file_name.split(\".\")[0] + \".pt\"\n",
    "        \n",
    "        tensors_lst.append(new_name)\n",
    "        \n",
    "        torch.save(temp_t, path_to_save + new_name)\n",
    "    \n",
    "    print(\"finished writing in the \" + path_to_save + \" folder!\")\n",
    "    \n",
    "    return tensors_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbre_of_classes = 41 \n",
    "b = torch.rand(32,nbre_of_classes, dtype=torch.float)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lab = torch.randint(0, nbre_of_classes, (b.size(0),))\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, mixup_percentage = mixup(b, lab, 0.4, nbre_of_classes, True, True)\n",
    "print(X)\n",
    "print(y)\n",
    "print(\"The mixup percentage is {}\".format(mixup_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then we take the max of the labels after loss evaluation:\n",
    "\n",
    "y.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter\n",
    "#torch.zeros(5, nbre_of_classes).scatter_(1, torch.zeros(5, nbre_of_classes).view(-1, 1).long(), 1)\n",
    "\n",
    "## Converts lab into onehot manually:\n",
    "one_hot = torch.zeros(lab.size(0), nbre_of_classes)\n",
    "for i in range (one_hot.size(0)):\n",
    "    one_hot[i][lab[i]]=1\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot(lab, nbre_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "\n",
    "input = X\n",
    "\n",
    "target = y.max(dim=1)[1]\n",
    "target_onehot = y\n",
    "output = loss(m(input), target)\n",
    "print(m(input))\n",
    "print(output)\n",
    "print(cost_onehot(m(input), target_onehot) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing trained models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## Loaded the list of indexes I already created:\n",
    "dictOfLabels = np.load(\"data_lists/labelsToNumberDict.npy\").item()\n",
    "\n",
    "## List of labels\n",
    "index = [0 for i in range (0, len(dictOfLabels))]\n",
    "\n",
    "## Putting the label in the right order\n",
    "for label, i in  dictOfLabels.items():\n",
    "    index[i] = label\n",
    "    \n",
    "print(index)\n",
    "print(' \\n')\n",
    "print(\"Number of different labels: {}\". format(len(index)))\n",
    "\n",
    "\n",
    "def confusion_matrix(model, dataloader, SincNetValid = False, size = len(index), name = \"Test\", cuda = True, index = index): \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    ## Iniotializes the confusion matrix:\n",
    "    mat = np.zeros([size,size])\n",
    "    total = 0\n",
    "    corr = 0\n",
    "    qty = [0]*size\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        \n",
    "        if SincNetValid:\n",
    "            inputs = inputs[0]\n",
    "        \n",
    "        if cuda:\n",
    "            inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.LongTensor)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        for k in range(labels.size(0)): # ground truth first (row) and then prediction (col)\n",
    "         # print(\"Here : \" +str(labels[k].item()) + \" ; \" + str(predicted[k].item()))\n",
    "            if(labels[k].item() == predicted[k].item()):\n",
    "                corr +=1\n",
    "            mat[labels[k].item(),predicted[k].item()]+=1\n",
    "            qty[labels[k].item()]+=1\n",
    "            \n",
    "    for k in range(size):\n",
    "        if(qty[k]!= 0):\n",
    "            mat[k] *= 1/qty[k]\n",
    "        \n",
    "    #model.train()\n",
    "    dataframe = pd.DataFrame(mat, index=index)\n",
    "    sn.set(font_scale=1)\n",
    "\n",
    "    fig=plt.figure(figsize=(15, 12), dpi= 400, facecolor='w', edgecolor='k')\n",
    "\n",
    "    \n",
    "    svm = sn.heatmap(dataframe, annot=False)\n",
    "    \n",
    "\n",
    "    figure = svm.get_figure()\n",
    "    figure.savefig('Images/Conf_Mat_' + name +'.png', dpi=400)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Added the accuracy:\n",
    "    percentage = np.array([mat[i, i] for i in range(0, len(mat))]).sum()/mat.sum()\n",
    "    \n",
    "    print(\"The accuracy on this sample is: {}\".format(percentage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, CNN_net, DNN1_net, DNN2_net):\n",
    "        super(Net, self).__init__()\n",
    "        self.CNN_net  = CNN_net\n",
    "        self.DNN1_net = DNN1_net\n",
    "        self.DNN2_net = DNN2_net\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.DNN2_net(self.DNN1_net(self.CNN_net(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(CNN_net, DNN1_net, DNN2_net)\n",
    "net.cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(net, train_loader, SincNetValid = False, name=\"NTF_Energy_Window1000_p7_class41\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
