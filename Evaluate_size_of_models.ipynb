{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims at evaluating the size of networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import configparser as ConfigParser\n",
    "\n",
    "## Local files imports:\n",
    "from Models import MLP, flip\n",
    "from Models import SincNet as CNN\n",
    "from Models import SincNet2D as CNN2D\n",
    "from read_conf_files import str_to_bool\n",
    "from utils import Dataset, LoadPrevModel\n",
    "from training_and_acc_fun import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options(object):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        '''Defines the cfg file'''\n",
    "        self.cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conf(config_file_path):\n",
    "    # Removed the possibility of executing with --cfg = path\n",
    "    # Instead we feed it directly\n",
    "\n",
    "    # Initializing dummy class with cfg folder path\n",
    "    options = Options(config_file_path)\n",
    "\n",
    "    # Reading the config file with config parser\n",
    "    Config = ConfigParser.ConfigParser()\n",
    "    Config.read(options.cfg)\n",
    "\n",
    "    #[data]\n",
    "    options.tr_lst=Config.get('data', 'tr_lst')\n",
    "    options.te_lst=Config.get('data', 'te_lst')\n",
    "    options.lab_dict=Config.get('data', 'lab_dict')\n",
    "    options.data_folder=Config.get('data', 'data_folder')\n",
    "    options.output_folder=Config.get('data', 'output_folder')\n",
    "    options.pt_file=Config.get('data', 'pt_file')\n",
    "\n",
    "    #[windowing]\n",
    "    options.fs=Config.get('windowing', 'fs')\n",
    "    options.cw_len=Config.get('windowing', 'cw_len')\n",
    "    options.cw_shift=Config.get('windowing', 'cw_shift')\n",
    "\n",
    "    if('cnn2D' in Config.sections()):\n",
    "        #[cnn2D]\n",
    "        options.is_conv2D = True\n",
    "        options.cnn_N_filt=Config.get('cnn2D', 'cnn_N_filt')\n",
    "        options.cnn_len_filt_W=Config.get('cnn2D', 'cnn_len_filt_W')\n",
    "        options.cnn_len_filt_H=Config.get('cnn2D', 'cnn_len_filt_H')\n",
    "        options.cnn_energy_L=Config.get('cnn2D', 'cnn_energy_L')\n",
    "        options.cnn_energy_stride=Config.get('cnn2D', 'cnn_energy_stride')\n",
    "        options.cnn_max_pool_len_W=Config.get('cnn2D', 'cnn_max_pool_len_W')\n",
    "        options.cnn_max_pool_len_H=Config.get('cnn2D', 'cnn_max_pool_len_H')\n",
    "        options.cnn_use_laynorm_inp=Config.get('cnn2D', 'cnn_use_laynorm_inp')\n",
    "        options.cnn_use_batchnorm_inp=Config.get('cnn2D', 'cnn_use_batchnorm_inp')\n",
    "        options.cnn_use_laynorm=Config.get('cnn2D', 'cnn_use_laynorm')\n",
    "        options.cnn_use_batchnorm=Config.get('cnn2D', 'cnn_use_batchnorm')\n",
    "        options.cnn_act=Config.get('cnn2D', 'cnn_act')\n",
    "        options.cnn_drop=Config.get('cnn2D', 'cnn_drop')\n",
    "    else:\n",
    "        #[cnn]\n",
    "        options.is_conv2D = False\n",
    "        options.cnn_N_filt=Config.get('cnn', 'cnn_N_filt')\n",
    "        options.cnn_len_filt=Config.get('cnn', 'cnn_len_filt')\n",
    "        options.cnn_max_pool_len=Config.get('cnn', 'cnn_max_pool_len')\n",
    "        options.cnn_use_laynorm_inp=Config.get('cnn', 'cnn_use_laynorm_inp')\n",
    "        options.cnn_use_batchnorm_inp=Config.get('cnn', 'cnn_use_batchnorm_inp')\n",
    "        options.cnn_use_laynorm=Config.get('cnn', 'cnn_use_laynorm')\n",
    "        options.cnn_use_batchnorm=Config.get('cnn', 'cnn_use_batchnorm')\n",
    "        options.cnn_act=Config.get('cnn', 'cnn_act')\n",
    "        options.cnn_drop=Config.get('cnn', 'cnn_drop')\n",
    "\n",
    "\n",
    "    #[dnn]\n",
    "    options.fc_lay=Config.get('dnn', 'fc_lay')\n",
    "    options.fc_drop=Config.get('dnn', 'fc_drop')\n",
    "    options.fc_use_laynorm_inp=Config.get('dnn', 'fc_use_laynorm_inp')\n",
    "    options.fc_use_batchnorm_inp=Config.get('dnn', 'fc_use_batchnorm_inp')\n",
    "    options.fc_use_batchnorm=Config.get('dnn', 'fc_use_batchnorm')\n",
    "    options.fc_use_laynorm=Config.get('dnn', 'fc_use_laynorm')\n",
    "    options.fc_act=Config.get('dnn', 'fc_act')\n",
    "\n",
    "    #[class]\n",
    "    options.class_lay=Config.get('class', 'class_lay')\n",
    "    options.class_drop=Config.get('class', 'class_drop')\n",
    "    options.class_use_laynorm_inp=Config.get('class', 'class_use_laynorm_inp')\n",
    "    options.class_use_batchnorm_inp=Config.get('class', 'class_use_batchnorm_inp')\n",
    "    options.class_use_batchnorm=Config.get('class', 'class_use_batchnorm')\n",
    "    options.class_use_laynorm=Config.get('class', 'class_use_laynorm')\n",
    "    options.class_act=Config.get('class', 'class_act')\n",
    "\n",
    "    #[optimization]\n",
    "    if('optimization' in Config.sections()):\n",
    "        options.lr=Config.get('optimization', 'lr')\n",
    "\n",
    "        ## use_scheduler:\n",
    "        if 'use_scheduler' in Config['optimization']:\n",
    "            options.use_scheduler=Config.get('optimization', 'use_scheduler')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `use_scheduler`, it is set to False.\")\n",
    "            options.use_scheduler='False'\n",
    "\n",
    "        ## scheduler_patience:\n",
    "        if 'scheduler_patience' in Config['optimization']:\n",
    "            options.scheduler_patience=Config.get('optimization', 'scheduler_patience')\n",
    "        else:\n",
    "            options.scheduler_patience=2\n",
    "            print(\"You did not specify the value of `scheduler_patience`, it is set to {}.\".format(options.scheduler_patience))\n",
    "\n",
    "        ## scheduler_factor:\n",
    "        if 'scheduler_factor' in Config['optimization']:\n",
    "            options.scheduler_factor=Config.get('optimization', 'scheduler_factor')\n",
    "        else:\n",
    "            options.scheduler_factor=0.5\n",
    "            print(\"You did not specify the value of `scheduler_factor`, it is set to {}.\".format(options.scheduler_factor))\n",
    "\n",
    "\n",
    "        options.batch_size=Config.get('optimization', 'batch_size')\n",
    "\n",
    "        ## Batch_dev:\n",
    "        if 'Batch_dev' in Config['optimization']:\n",
    "            options.Batch_dev=Config.get('optimization', 'Batch_dev')\n",
    "        else:\n",
    "            options.Batch_dev=32\n",
    "            print(\"You did not specify the value of `Batch_dev`, it is set to {}.\".format(options.Batch_dev))\n",
    "\n",
    "        ## patience:\n",
    "        if 'patience' in Config['optimization']:\n",
    "            options.patience=Config.get('optimization', 'patience')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `patience`, it is set to 7.\")\n",
    "            options.patience=7\n",
    "\n",
    "        options.N_epochs=Config.get('optimization', 'N_epochs')\n",
    "        options.N_batches=Config.get('optimization', 'N_batches')\n",
    "        options.N_eval_epoch=Config.get('optimization', 'N_eval_epoch')\n",
    "        \n",
    "        ## train_acc_period:\n",
    "        if 'train_acc_period' in Config['optimization']:\n",
    "                options.train_acc_period=Config.get('optimization', 'train_acc_period')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `train_acc_period`, it is set to 5.\")\n",
    "            options.train_acc_period=5\n",
    "        \n",
    "        ## fact_amp:        \n",
    "        if 'fact_amp' in Config['optimization']:\n",
    "                options.fact_amp=Config.get('optimization', 'fact_amp')\n",
    "        else:\n",
    "            options.fact_amp=0.2\n",
    "            print(\"You did not specify the value of `fact_amp`, it is set to {}.\".format(options.fact_amp))\n",
    "        \n",
    "        ## use_mixup:\n",
    "        if 'use_mixup' in Config['optimization']:\n",
    "            options.use_mixup=Config.get('optimization', 'use_mixup')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `use_mixup`, it is set to False.\")\n",
    "            options.use_mixup='False'\n",
    "        \n",
    "        ## mixup_batch_prop:        \n",
    "        if 'mixup_batch_prop' in Config['optimization']:\n",
    "            options.mixup_batch_prop=Config.get('optimization', 'mixup_batch_prop')\n",
    "        else:\n",
    "            options.mixup_batch_prop=float(1.0) if options.use_mixup=='True' else float(0.0)\n",
    "            print(\"You did not specify the value of `mixup_batch_prop`, it is set to {}%.\".format(options.mixup_batch_prop*100))\n",
    "        \n",
    "        ## beta_coef:\n",
    "        if 'beta_coef' in Config['optimization']:\n",
    "            options.beta_coef=Config.get('optimization', 'beta_coef')\n",
    "        else:\n",
    "            print(\"You did not specify the value of `beta_coef`, it is set to 0.4.\")\n",
    "            options.beta_coef=0.4\n",
    "        \n",
    "        ## same_classes:        \n",
    "        if 'same_classes' in Config['optimization']:\n",
    "            options.same_classes=Config.get('optimization', 'same_classes')\n",
    "        else:\n",
    "            options.same_classes='False'\n",
    "            print(\"You did not specify the value of `same_classes`, it is set to {}.\".format(options.same_classes))\n",
    "            if(\"True\" in options.use_mixup):\n",
    "                print(\"Warning: you are using mixup but you did not mention which type in config file. \\n\"+\n",
    "                    \"By default it will be set to False. You are advised to add a same_class attribute to your cfg file and set it to True or False.\")    \n",
    "\n",
    "            \n",
    "        options.seed=Config.get('optimization', 'seed')\n",
    "    else:\n",
    "        print(\"Error, you did not specify optimization parameters in your cfg. Consequently, the code won't run...\")\n",
    "\n",
    "    return options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did not specify the value of `fact_amp`, it is set to 0.2.\n",
      "You did not specify the value of `mixup_batch_prop`, it is set to 0.0%.\n",
      "exp/SincNet2D_DCASE/CNNlay4_Rand0PreEnergy4000ms_Scheduler0.2_Window3000ms_PReLu_Drop30\n",
      "Data/Audio_Tensors/Train/Preprocessed_withEnergy_AudioTensors_Window4000ms_Random0Padding/\n"
     ]
    }
   ],
   "source": [
    "# Config path location\n",
    "config_file_path = \"cfg/SincNet2D/SincNet2D_CNNLay4_Rand0PreEnergyWindow3000_Scheduler_PReLu_Drop30.cfg\"\n",
    "\n",
    "# Reading cfg file and storing its parameters into options :\n",
    "options=read_conf(config_file_path)\n",
    "\n",
    "print(options.output_folder)\n",
    "print(options.data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did not specify the value of `fact_amp`, it is set to 0.2.\n",
      "You did not specify the value of `mixup_batch_prop`, it is set to 0.0%.\n",
      "The file contains the config of a 2D convolutional network.\n"
     ]
    }
   ],
   "source": [
    "## <!>---------------------------- Reading the config file ----------------------------<!> ##\n",
    "# Reading cfg file\n",
    "options=read_conf(config_file_path)\n",
    "\n",
    "## Architecture of the file:\n",
    "#[data]\n",
    "pt_file=options.pt_file\n",
    "output_folder=options.output_folder\n",
    "\n",
    "#[windowing]\n",
    "fs=int(options.fs)\n",
    "cw_len=int(options.cw_len)\n",
    "cw_shift=int(options.cw_shift)\n",
    "\n",
    "is_conv2D = options.is_conv2D\n",
    "conv_type = '2D' if is_conv2D else '1D'\n",
    "print(\"The file contains the config of a {} convolutional network.\".format(conv_type))\n",
    "if is_conv2D:\n",
    "    #[cnn2D]\n",
    "    cnn_N_filt=list(map(int, options.cnn_N_filt.split(',')))\n",
    "    cnn_len_filt_W=list(map(int, options.cnn_len_filt_W.split(',')))\n",
    "    cnn_len_filt_H=list(map(int, options.cnn_len_filt_H.split(',')))\n",
    "    cnn_energy_L=int(options.cnn_energy_L)\n",
    "    cnn_energy_stride=int(options.cnn_energy_stride)\n",
    "    cnn_max_pool_len_W=list(map(int, options.cnn_max_pool_len_W.split(',')))\n",
    "    cnn_max_pool_len_H=list(map(int, options.cnn_max_pool_len_H.split(',')))\n",
    "else:\n",
    "    #[cnn]\n",
    "    cnn_N_filt=list(map(int, options.cnn_N_filt.split(',')))\n",
    "    cnn_len_filt=list(map(int, options.cnn_len_filt.split(',')))\n",
    "    cnn_max_pool_len=list(map(int, options.cnn_max_pool_len.split(',')))\n",
    "\n",
    "cnn_use_laynorm_inp=str_to_bool(options.cnn_use_laynorm_inp)\n",
    "cnn_use_batchnorm_inp=str_to_bool(options.cnn_use_batchnorm_inp)\n",
    "cnn_use_laynorm=list(map(str_to_bool, options.cnn_use_laynorm.split(',')))\n",
    "cnn_use_batchnorm=list(map(str_to_bool, options.cnn_use_batchnorm.split(',')))\n",
    "cnn_act=list(map(str, options.cnn_act.split(',')))\n",
    "cnn_drop=list(map(float, options.cnn_drop.split(',')))\n",
    "\n",
    "#[dnn]\n",
    "fc_lay=list(map(int, options.fc_lay.split(',')))\n",
    "fc_drop=list(map(float, options.fc_drop.split(',')))\n",
    "fc_use_laynorm_inp=str_to_bool(options.fc_use_laynorm_inp)\n",
    "fc_use_batchnorm_inp=str_to_bool(options.fc_use_batchnorm_inp)\n",
    "fc_use_batchnorm=list(map(str_to_bool, options.fc_use_batchnorm.split(',')))\n",
    "fc_use_laynorm=list(map(str_to_bool, options.fc_use_laynorm.split(',')))\n",
    "fc_act=list(map(str, options.fc_act.split(',')))\n",
    "\n",
    "#[class]\n",
    "class_lay=list(map(int, options.class_lay.split(',')))\n",
    "class_drop=list(map(float, options.class_drop.split(',')))\n",
    "class_use_laynorm_inp=str_to_bool(options.class_use_laynorm_inp)\n",
    "class_use_batchnorm_inp=str_to_bool(options.class_use_batchnorm_inp)\n",
    "class_use_batchnorm=list(map(str_to_bool, options.class_use_batchnorm.split(',')))\n",
    "class_use_laynorm=list(map(str_to_bool, options.class_use_laynorm.split(',')))\n",
    "class_act=list(map(str, options.class_act.split(',')))\n",
    "\n",
    "#[optimization]\n",
    "Batch_dev=int(options.Batch_dev)\n",
    "\n",
    "\n",
    "# Converting context and shift in samples\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "wshift=int(fs*cw_shift/1000.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting Cuda device... \t\tCuda device 1 was selected successfully!\n"
     ]
    }
   ],
   "source": [
    "## Setting cuda Device\n",
    "print(\"Selecting Cuda device... \\t\\t\", end=\"\")\n",
    "Desired_cuda_device_number = int(1)\n",
    "\n",
    "if torch.cuda.is_available(): # we'll use cuda\n",
    "    device = \"cuda:\"+str(Desired_cuda_device_number)\n",
    "    torch.cuda.set_device(device)\n",
    "    if(torch.cuda.current_device() == Desired_cuda_device_number and torch.cuda.is_available()):\n",
    "        print(\"Cuda device {} was selected successfully!\".format(Desired_cuda_device_number))\n",
    "    else:\n",
    "        print(\"Cuda was not selected successfully...\")\n",
    "else:\n",
    "    print(\"Cuda device(s) is(are) not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "cost = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the Networks... \t\tInitialization done!\n"
     ]
    }
   ],
   "source": [
    "## <!>------------------- Initializing the Networks with .cfg options -------------------<!> ##\n",
    "\n",
    "print(\"Initializing the Networks... \\t\\t\", end=\"\")\n",
    "# Feature extractor CNN\n",
    "if is_conv2D:\n",
    "    CNN_arch = {'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt_W': cnn_len_filt_W,\n",
    "            'cnn_len_filt_H': cnn_len_filt_H,\n",
    "            'cnn_energy_L': cnn_energy_L,\n",
    "            'cnn_energy_stride': cnn_energy_stride,\n",
    "            'cnn_max_pool_len_W': cnn_max_pool_len_W,\n",
    "            'cnn_max_pool_len_H': cnn_max_pool_len_H,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,          \n",
    "            }\n",
    "else:\n",
    "    CNN_arch = {'input_dim': wlen,\n",
    "            'fs': fs,\n",
    "            'cnn_N_filt': cnn_N_filt,\n",
    "            'cnn_len_filt': cnn_len_filt,\n",
    "            'cnn_max_pool_len':cnn_max_pool_len,\n",
    "            'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "            'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "            'cnn_use_laynorm':cnn_use_laynorm,\n",
    "            'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "            'cnn_act': cnn_act,\n",
    "            'cnn_drop':cnn_drop,          \n",
    "            }\n",
    "\n",
    "## Initializes SincNet:\n",
    "CNN_net=CNN2D(CNN_arch) if is_conv2D else CNN(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "\n",
    "#fc_lay = [2048]*3\n",
    "\n",
    "## First DNN, follows the config from the section [dnn] in .cfg file\n",
    "DNN1_arch = {'input_dim': CNN_net.out_dim,\n",
    "          'fc_lay': fc_lay,\n",
    "          'fc_drop': fc_drop, \n",
    "          'fc_use_batchnorm': fc_use_batchnorm,\n",
    "          'fc_use_laynorm': fc_use_laynorm,\n",
    "          'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "          'fc_act': fc_act,\n",
    "          }\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "\n",
    "## Last trainable layer, has softmax as activation function see section [class] in .cfg\n",
    "DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "          'fc_lay': class_lay,\n",
    "          'fc_drop': class_drop, \n",
    "          'fc_use_batchnorm': class_use_batchnorm,\n",
    "          'fc_use_laynorm': class_use_laynorm,\n",
    "          'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "          'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "\n",
    "print(\"Initialization done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainNet(nn.Module):\n",
    "\n",
    "    def __init__(self, CNN_net, DNN1_net, DNN2_net):\n",
    "        super(MainNet, self).__init__()\n",
    "        self.CNN_net  = CNN_net\n",
    "        self.DNN1_net = DNN1_net\n",
    "        self.DNN2_net = DNN2_net\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.DNN2_net(self.DNN1_net(self.CNN_net(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainNet(\n",
       "  (CNN_net): SincNet2D(\n",
       "    (conv): ModuleList(\n",
       "      (0): SincConv_fast()\n",
       "      (1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(80, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm2d(10, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm2d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm2d(20, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm(torch.Size([80, 31916]), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LayerNorm(torch.Size([10, 39, 353]), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LayerNorm(torch.Size([20, 18, 117]), eps=1e-05, elementwise_affine=True)\n",
       "      (3): LayerNorm(torch.Size([20, 16, 57]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): LeakyReLU(negative_slope=0.2)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "      (3): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.0)\n",
       "      (1): Dropout(p=0.0)\n",
       "      (2): Dropout(p=0.0)\n",
       "      (3): Dropout(p=0.0)\n",
       "    )\n",
       "    (ln0): LayerNorm(torch.Size([96000]), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (DNN1_net): MLP(\n",
       "    (wx): ModuleList(\n",
       "      (0): Linear(in_features=18240, out_features=1024, bias=True)\n",
       "      (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "      (2): LayerNorm()\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): PReLU(num_parameters=1)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.3)\n",
       "      (1): Dropout(p=0.3)\n",
       "      (2): Dropout(p=0.3)\n",
       "    )\n",
       "    (ln0): LayerNorm()\n",
       "  )\n",
       "  (DNN2_net): MLP(\n",
       "    (wx): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=41, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(41, eps=1e-05, momentum=0.05, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "    )\n",
       "    (act): ModuleList(\n",
       "      (0): LogSoftmax()\n",
       "    )\n",
       "    (drop): ModuleList(\n",
       "      (0): Dropout(p=0.0)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_net = MainNet(CNN_net, DNN1_net, DNN2_net)\n",
    "Main_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 96000,\n",
       " 'fs': 32000,\n",
       " 'cnn_N_filt': [80, 10, 20, 20],\n",
       " 'cnn_len_filt_W': [251, 3, 3, 3],\n",
       " 'cnn_len_filt_H': [0, 3, 3, 3],\n",
       " 'cnn_energy_L': 60,\n",
       " 'cnn_energy_stride': 30,\n",
       " 'cnn_max_pool_len_W': [3, 3, 3, 2],\n",
       " 'cnn_max_pool_len_H': [1, 2, 2, 1],\n",
       " 'cnn_use_laynorm_inp': True,\n",
       " 'cnn_use_batchnorm_inp': False,\n",
       " 'cnn_use_laynorm': [True, True, True, True],\n",
       " 'cnn_use_batchnorm': [False, False, False, False],\n",
       " 'cnn_act': ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'],\n",
       " 'cnn_drop': [0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 18240,\n",
       " 'fc_lay': [1024, 1024, 512],\n",
       " 'fc_drop': [0.3, 0.3, 0.3, 0.3],\n",
       " 'fc_use_batchnorm': [True, True, True],\n",
       " 'fc_use_laynorm': [False, False, False],\n",
       " 'fc_use_laynorm_inp': True,\n",
       " 'fc_use_batchnorm_inp': False,\n",
       " 'fc_act': ['prelu', 'prelu', 'prelu']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN1_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 512,\n",
       " 'fc_lay': [41],\n",
       " 'fc_drop': [0.0],\n",
       " 'fc_use_batchnorm': [False],\n",
       " 'fc_use_laynorm': [False],\n",
       " 'fc_use_laynorm_inp': False,\n",
       " 'fc_use_batchnorm_inp': False,\n",
       " 'fc_act': ['softmax']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN2_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "            \n",
    "        ## Splitting the name into processable data:\n",
    "        l        = name.split(\".\")\n",
    "\n",
    "        Net_name = l[0]\n",
    "        fun      = l[1]\n",
    "        num      = int(l[2]) if len(l[2])==1 else -1\n",
    "        \n",
    "        \n",
    "\n",
    "        if('bn' in fun):\n",
    "            if('CNN' in Net_name):\n",
    "                if(not CNN_arch['cnn_use_batchnorm'][num]):\n",
    "                    continue\n",
    "            elif('DNN1' in Net_name):\n",
    "                if(not DNN1_arch['fc_use_batchnorm'][num]):\n",
    "                    continue\n",
    "            elif('DNN2' in Net_name):\n",
    "                if(not DNN2_arch['fc_use_batchnorm'][num]):\n",
    "                    continue\n",
    "            \n",
    "        if('ln' in fun):\n",
    "            if('0' in fun):\n",
    "                if('CNN' in Net_name):\n",
    "                    if(not CNN_arch['cnn_use_laynorm_inp']):\n",
    "                        continue\n",
    "                elif('DNN1' in Net_name):\n",
    "                    if(not DNN1_arch['fc_use_laynorm_inp']):\n",
    "                        continue\n",
    "                elif('DNN2' in Net_name):\n",
    "                    if(not DNN2_arch['fc_use_laynorm_inp']):\n",
    "                        continue\n",
    "            else:\n",
    "                if('CNN' in Net_name):\n",
    "                    if(not CNN_arch['cnn_use_laynorm'][num]):\n",
    "                        continue\n",
    "                elif('DNN1' in Net_name):\n",
    "                    if(not DNN1_arch['fc_use_laynorm'][num]):\n",
    "                        continue                        \n",
    "                elif('DNN2' in Net_name):\n",
    "                    if(not DNN2_arch['fc_use_laynorm'][num]):\n",
    "                        continue\n",
    "            \n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------+\n",
      "|         Modules         | Parameters |\n",
      "+-------------------------+------------+\n",
      "|  CNN_net.conv.0.low_hz_ |     80     |\n",
      "| CNN_net.conv.0.band_hz_ |     80     |\n",
      "|  CNN_net.conv.1.weight  |     90     |\n",
      "|   CNN_net.conv.1.bias   |     10     |\n",
      "|  CNN_net.conv.2.weight  |    1800    |\n",
      "|   CNN_net.conv.2.bias   |     20     |\n",
      "|  CNN_net.conv.3.weight  |    3600    |\n",
      "|   CNN_net.conv.3.bias   |     20     |\n",
      "|   CNN_net.ln.0.weight   |  2553280   |\n",
      "|    CNN_net.ln.0.bias    |  2553280   |\n",
      "|   CNN_net.ln.1.weight   |   137670   |\n",
      "|    CNN_net.ln.1.bias    |   137670   |\n",
      "|   CNN_net.ln.2.weight   |   42120    |\n",
      "|    CNN_net.ln.2.bias    |   42120    |\n",
      "|   CNN_net.ln.3.weight   |   18240    |\n",
      "|    CNN_net.ln.3.bias    |   18240    |\n",
      "|    CNN_net.ln0.weight   |   96000    |\n",
      "|     CNN_net.ln0.bias    |   96000    |\n",
      "|   DNN1_net.wx.0.weight  |  18677760  |\n",
      "|    DNN1_net.wx.0.bias   |    1024    |\n",
      "|   DNN1_net.wx.1.weight  |  1048576   |\n",
      "|    DNN1_net.wx.1.bias   |    1024    |\n",
      "|   DNN1_net.wx.2.weight  |   524288   |\n",
      "|    DNN1_net.wx.2.bias   |    512     |\n",
      "|   DNN1_net.bn.0.weight  |    1024    |\n",
      "|    DNN1_net.bn.0.bias   |    1024    |\n",
      "|   DNN1_net.bn.1.weight  |    1024    |\n",
      "|    DNN1_net.bn.1.bias   |    1024    |\n",
      "|   DNN1_net.bn.2.weight  |    512     |\n",
      "|    DNN1_net.bn.2.bias   |    512     |\n",
      "|  DNN1_net.act.0.weight  |     1      |\n",
      "|  DNN1_net.act.1.weight  |     1      |\n",
      "|  DNN1_net.act.2.weight  |     1      |\n",
      "|    DNN1_net.ln0.gamma   |   18240    |\n",
      "|    DNN1_net.ln0.beta    |   18240    |\n",
      "|   DNN2_net.wx.0.weight  |   20992    |\n",
      "|    DNN2_net.wx.0.bias   |     41     |\n",
      "+-------------------------+------------+\n",
      "Total Trainable Params: 26016140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26016140"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(Main_net)# in_features=56220 * out_features=2048 = 115,138,560\n",
    "# in_features_4layCNN = 18660 = 312 * 60 = (935 -3 +1) /3 * Nbre_Filt\n",
    "# in_features_4layCNN = 18660 * out_features=1516 = 28,288,560  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('CNN_net.conv.0.low_hz_',\n",
       "              tensor([[   30.0000],\n",
       "                      [   59.0715],\n",
       "                      [   89.3007],\n",
       "                      [  120.7338],\n",
       "                      [  153.4186],\n",
       "                      [  187.4051],\n",
       "                      [  222.7451],\n",
       "                      [  259.4925],\n",
       "                      [  297.7032],\n",
       "                      [  337.4357],\n",
       "                      [  378.7505],\n",
       "                      [  421.7106],\n",
       "                      [  466.3816],\n",
       "                      [  512.8315],\n",
       "                      [  561.1312],\n",
       "                      [  611.3544],\n",
       "                      [  663.5778],\n",
       "                      [  717.8808],\n",
       "                      [  774.3464],\n",
       "                      [  833.0607],\n",
       "                      [  894.1132],\n",
       "                      [  957.5971],\n",
       "                      [ 1023.6092],\n",
       "                      [ 1092.2501],\n",
       "                      [ 1163.6246],\n",
       "                      [ 1237.8414],\n",
       "                      [ 1315.0139],\n",
       "                      [ 1395.2598],\n",
       "                      [ 1478.7013],\n",
       "                      [ 1565.4658],\n",
       "                      [ 1655.6855],\n",
       "                      [ 1749.4983],\n",
       "                      [ 1847.0470],\n",
       "                      [ 1948.4805],\n",
       "                      [ 2053.9534],\n",
       "                      [ 2163.6267],\n",
       "                      [ 2277.6675],\n",
       "                      [ 2396.2500],\n",
       "                      [ 2519.5549],\n",
       "                      [ 2647.7703],\n",
       "                      [ 2781.0918],\n",
       "                      [ 2919.7227],\n",
       "                      [ 3063.8743],\n",
       "                      [ 3213.7666],\n",
       "                      [ 3369.6282],\n",
       "                      [ 3531.6968],\n",
       "                      [ 3700.2197],\n",
       "                      [ 3875.4539],\n",
       "                      [ 4057.6665],\n",
       "                      [ 4247.1357],\n",
       "                      [ 4444.1499],\n",
       "                      [ 4649.0103],\n",
       "                      [ 4862.0293],\n",
       "                      [ 5083.5312],\n",
       "                      [ 5313.8540],\n",
       "                      [ 5553.3496],\n",
       "                      [ 5802.3828],\n",
       "                      [ 6061.3330],\n",
       "                      [ 6330.5962],\n",
       "                      [ 6610.5820],\n",
       "                      [ 6901.7183],\n",
       "                      [ 7204.4487],\n",
       "                      [ 7519.2354],\n",
       "                      [ 7846.5576],\n",
       "                      [ 8186.9155],\n",
       "                      [ 8540.8271],\n",
       "                      [ 8908.8340],\n",
       "                      [ 9291.4951],\n",
       "                      [ 9689.3965],\n",
       "                      [10103.1426],\n",
       "                      [10533.3662],\n",
       "                      [10980.7236],\n",
       "                      [11445.8965],\n",
       "                      [11929.5938],\n",
       "                      [12432.5537],\n",
       "                      [12955.5439],\n",
       "                      [13499.3623],\n",
       "                      [14064.8369],\n",
       "                      [14652.8311],\n",
       "                      [15264.2412]], device='cuda:0')),\n",
       "             ('CNN_net.conv.0.band_hz_',\n",
       "              tensor([[ 29.0715],\n",
       "                      [ 30.2292],\n",
       "                      [ 31.4331],\n",
       "                      [ 32.6849],\n",
       "                      [ 33.9865],\n",
       "                      [ 35.3400],\n",
       "                      [ 36.7474],\n",
       "                      [ 38.2108],\n",
       "                      [ 39.7325],\n",
       "                      [ 41.3148],\n",
       "                      [ 42.9601],\n",
       "                      [ 44.6709],\n",
       "                      [ 46.4499],\n",
       "                      [ 48.2997],\n",
       "                      [ 50.2232],\n",
       "                      [ 52.2233],\n",
       "                      [ 54.3031],\n",
       "                      [ 56.4656],\n",
       "                      [ 58.7143],\n",
       "                      [ 61.0525],\n",
       "                      [ 63.4839],\n",
       "                      [ 66.0121],\n",
       "                      [ 68.6409],\n",
       "                      [ 71.3745],\n",
       "                      [ 74.2169],\n",
       "                      [ 77.1725],\n",
       "                      [ 80.2458],\n",
       "                      [ 83.4415],\n",
       "                      [ 86.7645],\n",
       "                      [ 90.2198],\n",
       "                      [ 93.8127],\n",
       "                      [ 97.5487],\n",
       "                      [101.4335],\n",
       "                      [105.4729],\n",
       "                      [109.6733],\n",
       "                      [114.0409],\n",
       "                      [118.5825],\n",
       "                      [123.3049],\n",
       "                      [128.2154],\n",
       "                      [133.3214],\n",
       "                      [138.6308],\n",
       "                      [144.1516],\n",
       "                      [149.8923],\n",
       "                      [155.8616],\n",
       "                      [162.0687],\n",
       "                      [168.5229],\n",
       "                      [175.2341],\n",
       "                      [182.2126],\n",
       "                      [189.4691],\n",
       "                      [197.0145],\n",
       "                      [204.8604],\n",
       "                      [213.0187],\n",
       "                      [221.5020],\n",
       "                      [230.3230],\n",
       "                      [239.4954],\n",
       "                      [249.0331],\n",
       "                      [258.9505],\n",
       "                      [269.2630],\n",
       "                      [279.9861],\n",
       "                      [291.1362],\n",
       "                      [302.7304],\n",
       "                      [314.7863],\n",
       "                      [327.3224],\n",
       "                      [340.3577],\n",
       "                      [353.9120],\n",
       "                      [368.0062],\n",
       "                      [382.6617],\n",
       "                      [397.9008],\n",
       "                      [413.7468],\n",
       "                      [430.2238],\n",
       "                      [447.3570],\n",
       "                      [465.1725],\n",
       "                      [483.6975],\n",
       "                      [502.9603],\n",
       "                      [522.9902],\n",
       "                      [543.8177],\n",
       "                      [565.4747],\n",
       "                      [587.9941],\n",
       "                      [611.4103],\n",
       "                      [635.7591]], device='cuda:0')),\n",
       "             ('CNN_net.conv.1.weight',\n",
       "              tensor([[[ 0.0092, -0.0054, -0.0096,  0.0460, -0.0163],\n",
       "                       [ 0.0479, -0.0402,  0.0283, -0.0113, -0.0457],\n",
       "                       [-0.0323, -0.0149, -0.0257, -0.0174,  0.0263],\n",
       "                       ...,\n",
       "                       [-0.0480, -0.0499, -0.0426, -0.0184,  0.0158],\n",
       "                       [-0.0047,  0.0034, -0.0215, -0.0139,  0.0132],\n",
       "                       [-0.0277,  0.0246,  0.0210,  0.0062,  0.0090]],\n",
       "              \n",
       "                      [[ 0.0361,  0.0335, -0.0274, -0.0116,  0.0010],\n",
       "                       [ 0.0355, -0.0279,  0.0334, -0.0072, -0.0318],\n",
       "                       [-0.0436,  0.0133,  0.0441, -0.0193,  0.0411],\n",
       "                       ...,\n",
       "                       [-0.0387, -0.0246,  0.0170, -0.0449, -0.0268],\n",
       "                       [-0.0036, -0.0223,  0.0233, -0.0410, -0.0154],\n",
       "                       [-0.0413,  0.0102, -0.0467, -0.0038,  0.0371]],\n",
       "              \n",
       "                      [[ 0.0463, -0.0135,  0.0219,  0.0451,  0.0192],\n",
       "                       [-0.0146,  0.0071, -0.0129, -0.0125, -0.0226],\n",
       "                       [ 0.0060, -0.0052,  0.0256, -0.0300, -0.0196],\n",
       "                       ...,\n",
       "                       [ 0.0288,  0.0004, -0.0273,  0.0498, -0.0047],\n",
       "                       [-0.0364,  0.0030,  0.0259,  0.0390,  0.0069],\n",
       "                       [ 0.0401, -0.0122, -0.0273,  0.0440, -0.0020]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0328,  0.0002,  0.0090,  0.0454,  0.0140],\n",
       "                       [-0.0189, -0.0096, -0.0233,  0.0406, -0.0283],\n",
       "                       [-0.0483, -0.0420, -0.0172, -0.0387,  0.0427],\n",
       "                       ...,\n",
       "                       [-0.0256,  0.0024,  0.0090, -0.0068,  0.0100],\n",
       "                       [-0.0396,  0.0057, -0.0331,  0.0305,  0.0309],\n",
       "                       [ 0.0493, -0.0427,  0.0420, -0.0098, -0.0305]],\n",
       "              \n",
       "                      [[-0.0425,  0.0289, -0.0164, -0.0423, -0.0434],\n",
       "                       [ 0.0457, -0.0126, -0.0332, -0.0452, -0.0398],\n",
       "                       [-0.0162, -0.0289, -0.0437, -0.0069,  0.0418],\n",
       "                       ...,\n",
       "                       [ 0.0073, -0.0228, -0.0300, -0.0444, -0.0369],\n",
       "                       [ 0.0370,  0.0277, -0.0429,  0.0307, -0.0047],\n",
       "                       [ 0.0145, -0.0285, -0.0212,  0.0349,  0.0163]],\n",
       "              \n",
       "                      [[ 0.0388, -0.0046,  0.0278,  0.0169,  0.0360],\n",
       "                       [ 0.0404,  0.0122, -0.0399, -0.0312,  0.0119],\n",
       "                       [ 0.0210,  0.0489, -0.0011, -0.0275, -0.0365],\n",
       "                       ...,\n",
       "                       [-0.0103,  0.0037, -0.0127,  0.0002,  0.0292],\n",
       "                       [-0.0099,  0.0104, -0.0021,  0.0400, -0.0283],\n",
       "                       [-0.0042, -0.0499, -0.0113,  0.0023, -0.0149]]], device='cuda:0')),\n",
       "             ('CNN_net.conv.1.bias',\n",
       "              tensor([ 2.9136e-02,  1.6246e-02,  1.9716e-02, -2.7158e-03, -4.6327e-02,\n",
       "                      -3.0764e-02, -8.2225e-03, -2.7968e-02,  3.0642e-02, -1.6536e-02,\n",
       "                      -3.7331e-02, -2.0382e-02,  8.1713e-03, -2.7711e-02,  4.0731e-02,\n",
       "                      -2.6825e-02,  3.0327e-02,  3.1286e-02,  4.9585e-02,  1.5338e-02,\n",
       "                       1.6639e-02,  7.4233e-03, -2.2259e-02, -2.1213e-02, -7.5530e-03,\n",
       "                      -2.4011e-03,  4.8849e-03,  1.6006e-02, -9.7155e-03,  4.1934e-02,\n",
       "                      -2.9502e-02,  3.7282e-02, -1.6122e-02,  3.3746e-02, -9.7940e-03,\n",
       "                      -1.1497e-02,  3.7354e-02,  3.0178e-02, -2.2280e-02,  8.4286e-03,\n",
       "                       4.3435e-02, -3.3916e-02,  2.9218e-02, -2.5463e-03, -4.0605e-02,\n",
       "                      -1.0787e-02, -4.7396e-02, -4.0017e-03, -4.6141e-02,  1.0375e-02,\n",
       "                       3.6946e-02, -1.3524e-02,  2.7086e-02, -3.9547e-02,  8.7477e-05,\n",
       "                       1.3668e-02, -2.1075e-02,  1.3588e-02, -6.1513e-03, -3.2265e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('CNN_net.conv.2.weight',\n",
       "              tensor([[[-0.0241, -0.0209, -0.0576, -0.0445, -0.0367],\n",
       "                       [-0.0572, -0.0513,  0.0563, -0.0104,  0.0117],\n",
       "                       [ 0.0442, -0.0109, -0.0196,  0.0035,  0.0562],\n",
       "                       ...,\n",
       "                       [-0.0265, -0.0351,  0.0108,  0.0176,  0.0245],\n",
       "                       [ 0.0320, -0.0070, -0.0009, -0.0069,  0.0034],\n",
       "                       [-0.0059,  0.0062,  0.0065,  0.0231, -0.0077]],\n",
       "              \n",
       "                      [[ 0.0452, -0.0543,  0.0274,  0.0183, -0.0394],\n",
       "                       [ 0.0498,  0.0321, -0.0514, -0.0381, -0.0443],\n",
       "                       [ 0.0155, -0.0325,  0.0012,  0.0541, -0.0575],\n",
       "                       ...,\n",
       "                       [-0.0498, -0.0115, -0.0325, -0.0330,  0.0082],\n",
       "                       [ 0.0385, -0.0462, -0.0331,  0.0071, -0.0236],\n",
       "                       [ 0.0388, -0.0164, -0.0574,  0.0213,  0.0452]],\n",
       "              \n",
       "                      [[ 0.0243,  0.0356, -0.0284,  0.0148,  0.0572],\n",
       "                       [-0.0344,  0.0297, -0.0435,  0.0545,  0.0181],\n",
       "                       [-0.0520,  0.0013, -0.0107,  0.0307,  0.0556],\n",
       "                       ...,\n",
       "                       [ 0.0152,  0.0316,  0.0501, -0.0192, -0.0373],\n",
       "                       [-0.0573,  0.0433, -0.0219, -0.0437,  0.0113],\n",
       "                       [ 0.0077, -0.0073, -0.0298, -0.0472,  0.0288]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0554, -0.0150,  0.0486, -0.0532,  0.0348],\n",
       "                       [ 0.0084, -0.0524,  0.0260, -0.0120,  0.0577],\n",
       "                       [-0.0419,  0.0299,  0.0504, -0.0568,  0.0081],\n",
       "                       ...,\n",
       "                       [ 0.0423, -0.0016,  0.0448, -0.0174, -0.0384],\n",
       "                       [ 0.0453, -0.0073, -0.0024,  0.0024,  0.0217],\n",
       "                       [-0.0483,  0.0486, -0.0105,  0.0056, -0.0194]],\n",
       "              \n",
       "                      [[ 0.0123,  0.0178, -0.0511, -0.0334,  0.0069],\n",
       "                       [-0.0259,  0.0499,  0.0107,  0.0389, -0.0319],\n",
       "                       [ 0.0031, -0.0391, -0.0038,  0.0228, -0.0319],\n",
       "                       ...,\n",
       "                       [-0.0191,  0.0245,  0.0390,  0.0200,  0.0269],\n",
       "                       [ 0.0358,  0.0176, -0.0340,  0.0399, -0.0516],\n",
       "                       [-0.0431,  0.0368,  0.0355, -0.0485,  0.0175]],\n",
       "              \n",
       "                      [[ 0.0196,  0.0222,  0.0544, -0.0224,  0.0070],\n",
       "                       [ 0.0526,  0.0345, -0.0245,  0.0477,  0.0291],\n",
       "                       [ 0.0503,  0.0135, -0.0411,  0.0513,  0.0411],\n",
       "                       ...,\n",
       "                       [ 0.0276,  0.0054,  0.0163, -0.0170, -0.0339],\n",
       "                       [-0.0484, -0.0553,  0.0488,  0.0243, -0.0195],\n",
       "                       [-0.0527, -0.0417,  0.0402, -0.0507,  0.0419]]], device='cuda:0')),\n",
       "             ('CNN_net.conv.2.bias',\n",
       "              tensor([ 0.0061, -0.0456,  0.0519, -0.0035, -0.0296, -0.0195,  0.0562, -0.0242,\n",
       "                       0.0525, -0.0229,  0.0299,  0.0054, -0.0198,  0.0326, -0.0230,  0.0209,\n",
       "                       0.0023,  0.0484,  0.0185,  0.0523,  0.0390,  0.0543,  0.0372, -0.0382,\n",
       "                      -0.0141,  0.0497,  0.0462, -0.0210,  0.0401, -0.0284,  0.0360, -0.0101,\n",
       "                       0.0205,  0.0279, -0.0496, -0.0160,  0.0247,  0.0463, -0.0020, -0.0077,\n",
       "                       0.0138, -0.0478, -0.0116, -0.0525,  0.0015,  0.0132,  0.0316, -0.0012,\n",
       "                      -0.0482, -0.0540, -0.0063, -0.0435, -0.0302, -0.0145,  0.0157, -0.0079,\n",
       "                       0.0093, -0.0153,  0.0570, -0.0463], device='cuda:0')),\n",
       "             ('CNN_net.bn.0.weight',\n",
       "              tensor([0.8108, 0.3054, 0.9201, 0.3507, 0.2000, 0.9667, 0.8752, 0.3993, 0.3948,\n",
       "                      0.8779, 0.2402, 0.1732, 0.2912, 0.2739, 0.5257, 0.5779, 0.7853, 0.5593,\n",
       "                      0.2488, 0.0705, 0.7715, 0.5761, 0.7316, 0.0043, 0.9455, 0.8670, 0.4945,\n",
       "                      0.8550, 0.5548, 0.2156, 0.8843, 0.1008, 0.0213, 0.6109, 0.9767, 0.7100,\n",
       "                      0.2337, 0.9431, 0.6251, 0.8763, 0.4639, 0.1088, 0.6592, 0.5437, 0.8408,\n",
       "                      0.1795, 0.4032, 0.6955, 0.1566, 0.2611, 0.8262, 0.5887, 0.6789, 0.8888,\n",
       "                      0.1909, 0.8064, 0.8717, 0.4341, 0.6348, 0.8729, 0.8455, 0.4998, 0.0029,\n",
       "                      0.0462, 0.0659, 0.7868, 0.7951, 0.5270, 0.4493, 0.4189, 0.1783, 0.2039,\n",
       "                      0.6390, 0.0136, 0.7624, 0.6004, 0.8422, 0.3983, 0.1132, 0.7743],\n",
       "                     device='cuda:0')),\n",
       "             ('CNN_net.bn.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.0.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.0.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('CNN_net.bn.0.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('CNN_net.bn.1.weight',\n",
       "              tensor([0.3453, 0.2451, 0.8501, 0.7124, 0.6785, 0.9322, 0.9342, 0.2683, 0.0730,\n",
       "                      0.1908, 0.7651, 0.7346, 0.0431, 0.7148, 0.4414, 0.1638, 0.0281, 0.1217,\n",
       "                      0.9304, 0.0748, 0.3738, 0.8226, 0.6304, 0.7195, 0.8845, 0.0937, 0.6187,\n",
       "                      0.9835, 0.6106, 0.1431, 0.3991, 0.0220, 0.4168, 0.7399, 0.0684, 0.1978,\n",
       "                      0.5280, 0.6543, 0.7167, 0.3264, 0.6340, 0.9649, 0.6568, 0.7307, 0.8103,\n",
       "                      0.4745, 0.8712, 0.9279, 0.9204, 0.0753, 0.1866, 0.7670, 0.6696, 0.1830,\n",
       "                      0.9173, 0.3737, 0.0032, 0.0108, 0.1819, 0.8122], device='cuda:0')),\n",
       "             ('CNN_net.bn.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.1.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.1.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('CNN_net.bn.1.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('CNN_net.bn.2.weight',\n",
       "              tensor([0.7991, 0.5029, 0.9964, 0.4140, 0.4477, 0.1376, 0.2879, 0.6963, 0.5424,\n",
       "                      0.0468, 0.6739, 0.9325, 0.7243, 0.0189, 0.4283, 0.1639, 0.1157, 0.9408,\n",
       "                      0.1430, 0.7844, 0.2617, 0.4148, 0.2481, 0.1068, 0.2201, 0.3450, 0.0887,\n",
       "                      0.8734, 0.6643, 0.1202, 0.5561, 0.7611, 0.4135, 0.8564, 0.6846, 0.5384,\n",
       "                      0.4242, 0.2129, 0.6172, 0.9178, 0.2579, 0.4885, 0.9180, 0.8484, 0.3014,\n",
       "                      0.0524, 0.9730, 0.5477, 0.7945, 0.2440, 0.8039, 0.4686, 0.8756, 0.0505,\n",
       "                      0.2173, 0.0023, 0.6266, 0.6126, 0.7348, 0.6828], device='cuda:0')),\n",
       "             ('CNN_net.bn.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('CNN_net.bn.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('CNN_net.bn.2.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('CNN_net.ln.0.gamma',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')),\n",
       "             ('CNN_net.ln.0.beta',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')),\n",
       "             ('CNN_net.ln.1.gamma',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')),\n",
       "             ('CNN_net.ln.1.beta',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')),\n",
       "             ('CNN_net.ln.2.gamma',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')),\n",
       "             ('CNN_net.ln.2.beta',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')),\n",
       "             ('CNN_net.ln0.gamma',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('CNN_net.ln0.beta',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.wx.0.weight',\n",
       "              tensor([[-2.2408e-04, -1.1274e-04,  3.5345e-04,  ..., -2.3538e-04,\n",
       "                       -1.7568e-04,  1.8013e-04],\n",
       "                      [ 2.3606e-05, -2.8553e-04,  3.1190e-04,  ..., -2.6724e-04,\n",
       "                       -3.1821e-04,  1.9574e-04],\n",
       "                      [ 1.8898e-04, -3.6687e-04,  1.1775e-04,  ..., -2.7164e-04,\n",
       "                       -7.5312e-05,  9.6147e-05],\n",
       "                      ...,\n",
       "                      [ 3.2644e-04,  1.8136e-05,  2.0713e-04,  ...,  1.7331e-04,\n",
       "                       -1.5549e-04, -1.6864e-04],\n",
       "                      [ 1.6463e-04,  2.2925e-04,  3.2500e-05,  ...,  8.3843e-05,\n",
       "                       -3.1070e-04,  2.0858e-04],\n",
       "                      [ 3.5891e-04, -3.7030e-04,  2.3402e-04,  ..., -3.4215e-04,\n",
       "                       -6.7600e-05,  2.4865e-05]], device='cuda:0')),\n",
       "             ('DNN1_net.wx.0.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.wx.1.weight',\n",
       "              tensor([[ 1.2956e-03, -9.9373e-04,  1.9503e-04,  ..., -1.6582e-03,\n",
       "                       -1.2217e-03, -2.4241e-04],\n",
       "                      [-1.3102e-03,  1.2484e-03,  1.3432e-03,  ..., -2.3342e-04,\n",
       "                        4.6171e-04, -5.0040e-04],\n",
       "                      [ 6.7821e-04,  2.2317e-04, -1.0326e-04,  ..., -1.2930e-03,\n",
       "                        5.5187e-05, -1.5105e-03],\n",
       "                      ...,\n",
       "                      [-2.2614e-04,  1.5089e-03,  1.7763e-03,  ...,  4.3554e-04,\n",
       "                        1.0978e-03,  2.1288e-04],\n",
       "                      [ 7.6269e-04, -8.4457e-04,  7.1022e-04,  ..., -2.8574e-04,\n",
       "                       -3.0983e-04,  7.0277e-04],\n",
       "                      [ 3.5509e-04,  3.6301e-04,  1.0603e-04,  ..., -9.8319e-04,\n",
       "                       -3.7109e-04,  6.7227e-04]], device='cuda:0')),\n",
       "             ('DNN1_net.wx.1.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.wx.2.weight',\n",
       "              tensor([[ 0.0023,  0.0011, -0.0023,  ..., -0.0021, -0.0001,  0.0010],\n",
       "                      [-0.0006,  0.0018,  0.0014,  ..., -0.0009,  0.0016,  0.0006],\n",
       "                      [ 0.0006,  0.0014, -0.0010,  ..., -0.0024, -0.0008, -0.0003],\n",
       "                      ...,\n",
       "                      [-0.0014, -0.0018,  0.0008,  ..., -0.0013, -0.0024,  0.0022],\n",
       "                      [ 0.0025, -0.0013,  0.0006,  ..., -0.0005, -0.0023, -0.0011],\n",
       "                      [-0.0002,  0.0010,  0.0011,  ..., -0.0020, -0.0018, -0.0002]],\n",
       "                     device='cuda:0')),\n",
       "             ('DNN1_net.wx.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.0.weight',\n",
       "              tensor([0.5416, 0.1700, 0.6971,  ..., 0.3276, 0.8405, 0.0969], device='cuda:0')),\n",
       "             ('DNN1_net.bn.0.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.0.running_mean',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.0.running_var',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.0.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('DNN1_net.bn.1.weight',\n",
       "              tensor([0.3360, 0.1677, 0.2869,  ..., 0.2934, 0.3411, 0.3457], device='cuda:0')),\n",
       "             ('DNN1_net.bn.1.bias',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.1.running_mean',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.1.running_var',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.1.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('DNN1_net.bn.2.weight',\n",
       "              tensor([7.3620e-01, 6.4465e-01, 5.6012e-01, 3.0309e-01, 8.0264e-01, 9.9308e-01,\n",
       "                      6.5131e-02, 3.0640e-01, 3.9836e-02, 4.8912e-01, 9.6209e-01, 9.7885e-01,\n",
       "                      3.5990e-03, 1.5959e-01, 9.0251e-01, 5.4690e-01, 2.7869e-01, 5.6866e-01,\n",
       "                      9.6159e-01, 1.0623e-01, 3.3082e-01, 5.8876e-01, 5.3817e-01, 5.2946e-01,\n",
       "                      3.5436e-01, 6.4473e-01, 1.0887e-01, 7.9624e-01, 8.7586e-01, 2.7402e-01,\n",
       "                      3.4004e-01, 9.2449e-01, 9.4994e-01, 1.8522e-01, 8.5105e-01, 1.5978e-01,\n",
       "                      6.7049e-01, 4.9045e-01, 5.1609e-01, 7.6422e-01, 7.9919e-02, 1.0055e-01,\n",
       "                      8.7547e-01, 9.2620e-01, 9.6751e-01, 7.1550e-01, 5.9473e-01, 9.2699e-02,\n",
       "                      9.6945e-01, 7.1249e-01, 3.9149e-01, 9.8453e-02, 8.5301e-01, 9.3728e-01,\n",
       "                      8.4795e-01, 1.9495e-01, 8.7040e-01, 1.1993e-01, 5.5712e-01, 7.8418e-02,\n",
       "                      2.0433e-01, 5.7551e-01, 1.6088e-01, 2.6501e-01, 6.0599e-01, 8.9976e-01,\n",
       "                      3.6744e-01, 4.7391e-02, 4.8051e-01, 8.2153e-01, 1.7209e-01, 5.7952e-01,\n",
       "                      1.4728e-01, 1.6636e-01, 4.9445e-01, 8.5729e-01, 7.6418e-01, 5.2707e-01,\n",
       "                      3.1349e-01, 1.6407e-01, 5.7464e-01, 5.1221e-01, 8.0977e-02, 9.7241e-01,\n",
       "                      8.6797e-01, 7.0687e-01, 9.4103e-01, 4.5524e-02, 3.1063e-01, 2.6629e-01,\n",
       "                      9.1691e-01, 7.1230e-01, 8.2426e-01, 7.3609e-01, 5.8955e-01, 1.3362e-01,\n",
       "                      4.8588e-01, 1.7055e-01, 8.5328e-01, 2.1638e-02, 7.0557e-01, 1.3685e-01,\n",
       "                      8.8747e-01, 6.8573e-01, 9.3460e-01, 6.4195e-01, 5.2073e-01, 7.4020e-01,\n",
       "                      2.0805e-01, 4.1085e-01, 1.8180e-01, 4.2055e-01, 2.4425e-01, 5.4487e-02,\n",
       "                      7.1098e-01, 3.9488e-01, 7.4411e-01, 8.2802e-01, 2.6457e-01, 9.4508e-01,\n",
       "                      8.0764e-01, 6.7864e-01, 6.4590e-01, 1.9694e-01, 3.4748e-01, 2.1722e-01,\n",
       "                      8.2082e-01, 3.2265e-01, 5.7829e-01, 1.6522e-01, 8.5539e-01, 5.9650e-01,\n",
       "                      4.7417e-01, 8.3713e-01, 7.1674e-01, 7.7751e-01, 3.7048e-01, 9.4592e-01,\n",
       "                      7.6698e-01, 2.5700e-01, 2.5398e-02, 4.0007e-01, 1.3339e-01, 8.3849e-03,\n",
       "                      5.3121e-01, 9.6944e-01, 7.8229e-02, 9.4944e-01, 8.4087e-02, 4.4747e-01,\n",
       "                      4.5254e-01, 4.5083e-01, 4.6167e-01, 9.8154e-01, 2.4426e-01, 8.0437e-01,\n",
       "                      1.7248e-01, 5.0247e-01, 1.0524e-01, 5.0917e-01, 7.0926e-01, 4.6206e-01,\n",
       "                      5.8308e-01, 8.9139e-04, 9.0302e-01, 6.8810e-01, 9.1968e-01, 1.4731e-01,\n",
       "                      4.5359e-03, 3.9691e-02, 2.4111e-01, 7.4788e-01, 3.9797e-01, 4.0670e-01,\n",
       "                      3.2007e-01, 6.0716e-01, 7.9027e-01, 4.9414e-01, 6.6524e-02, 9.2892e-01,\n",
       "                      4.1414e-01, 9.8235e-01, 7.3790e-01, 6.8631e-01, 4.9551e-01, 8.0439e-01,\n",
       "                      2.9449e-01, 7.7820e-01, 1.6924e-01, 9.2815e-01, 7.0163e-02, 2.7591e-01,\n",
       "                      2.4833e-01, 1.7312e-02, 8.7766e-01, 5.0792e-01, 8.7614e-01, 8.0110e-01,\n",
       "                      8.8910e-01, 7.3644e-01, 3.4618e-01, 1.8397e-01, 3.5310e-01, 8.3043e-01,\n",
       "                      6.8434e-01, 1.4885e-01, 3.9228e-01, 8.2824e-02, 1.1647e-01, 3.9339e-01,\n",
       "                      2.3565e-01, 6.2152e-01, 7.5902e-02, 4.6197e-01, 3.9158e-02, 1.9895e-01,\n",
       "                      1.5074e-01, 6.6122e-01, 9.5021e-01, 9.1173e-01, 7.5553e-01, 1.8242e-01,\n",
       "                      7.8993e-01, 7.9248e-02, 9.8095e-01, 1.4703e-01, 2.4305e-01, 3.7416e-01,\n",
       "                      3.8783e-01, 2.7737e-01, 1.6075e-01, 8.8254e-01, 9.1467e-01, 1.3494e-01,\n",
       "                      5.8008e-01, 3.0785e-01, 4.3298e-01, 6.7639e-01, 1.1127e-01, 9.2650e-01,\n",
       "                      4.1745e-01, 3.3506e-01, 3.3760e-01, 6.6321e-01, 6.7930e-01, 8.9379e-01,\n",
       "                      4.1140e-01, 6.0056e-01, 6.6038e-01, 2.2813e-01, 3.8261e-01, 5.7806e-01,\n",
       "                      8.9832e-01, 7.4897e-01, 2.4383e-01, 5.8671e-01, 4.9430e-01, 3.9619e-01,\n",
       "                      9.6362e-01, 1.7368e-01, 5.7497e-01, 7.6772e-01, 8.8389e-01, 1.7720e-01,\n",
       "                      6.7999e-01, 1.4439e-03, 5.7853e-01, 2.0229e-01, 9.9158e-01, 9.4347e-01,\n",
       "                      7.1106e-01, 3.8368e-01, 1.6335e-01, 4.2138e-01, 3.5372e-01, 9.5188e-01,\n",
       "                      1.1922e-01, 8.0441e-01, 6.0741e-01, 1.8547e-01, 4.3224e-01, 5.1611e-02,\n",
       "                      1.3800e-01, 3.5009e-01, 1.9292e-01, 2.7691e-01, 1.8863e-01, 5.8266e-01,\n",
       "                      8.0589e-01, 3.7143e-01, 6.3342e-01, 6.5898e-01, 8.1017e-01, 7.7849e-01,\n",
       "                      2.1077e-01, 6.7802e-01, 3.9952e-01, 5.2913e-01, 5.6752e-01, 5.8674e-01,\n",
       "                      8.9429e-01, 2.2276e-01, 1.3888e-01, 1.7708e-01, 7.1218e-01, 7.5628e-01,\n",
       "                      3.7681e-01, 5.9661e-01, 2.0753e-01, 4.0366e-01, 6.6065e-01, 9.1454e-01,\n",
       "                      5.7971e-01, 8.6771e-03, 8.7229e-01, 7.0251e-01, 2.7775e-01, 9.0740e-01,\n",
       "                      7.8204e-01, 7.5215e-01, 9.3636e-01, 4.1904e-02, 9.3577e-01, 9.1181e-02,\n",
       "                      7.1863e-01, 3.8051e-02, 1.7299e-01, 9.2426e-01, 9.3232e-01, 4.3921e-01,\n",
       "                      8.5083e-01, 6.4318e-01, 5.6155e-01, 8.6621e-01, 4.8693e-01, 5.2198e-01,\n",
       "                      2.6732e-01, 3.9522e-01, 6.1502e-02, 3.9431e-01, 7.1897e-01, 2.2825e-01,\n",
       "                      7.8923e-01, 5.9888e-01, 1.2311e-01, 2.0938e-01, 4.4966e-01, 4.4234e-01,\n",
       "                      4.3674e-01, 7.1999e-01, 3.7168e-01, 5.8920e-01, 3.5099e-01, 1.7927e-01,\n",
       "                      6.6578e-01, 8.1866e-01, 9.7998e-01, 9.5184e-01, 5.6498e-01, 6.0311e-01,\n",
       "                      9.0048e-01, 6.5069e-01, 5.4682e-01, 8.2436e-01, 4.4639e-01, 4.4530e-01,\n",
       "                      9.7364e-01, 6.2642e-01, 3.9424e-01, 9.8132e-01, 3.1620e-02, 5.3842e-01,\n",
       "                      9.7173e-01, 6.7366e-01, 3.5937e-01, 4.1422e-01, 9.5613e-01, 6.0217e-01,\n",
       "                      9.0847e-01, 6.7835e-01, 5.5176e-01, 3.3402e-01, 5.7440e-01, 7.8417e-01,\n",
       "                      6.4339e-01, 8.0179e-01, 8.3244e-01, 8.0059e-01, 5.2040e-01, 7.9128e-01,\n",
       "                      9.5616e-02, 3.2226e-01, 4.4873e-01, 4.4511e-01, 8.5933e-01, 3.1698e-01,\n",
       "                      5.7372e-01, 9.8753e-01, 4.8460e-01, 9.6957e-01, 1.0960e-01, 9.0422e-01,\n",
       "                      1.9423e-01, 6.2216e-01, 1.1587e-01, 5.3425e-01, 1.0525e-01, 8.9332e-01,\n",
       "                      3.8031e-02, 9.7031e-01, 3.7224e-01, 9.9922e-01, 4.3090e-01, 9.0854e-01,\n",
       "                      9.2308e-01, 5.4818e-01, 4.0614e-01, 7.9998e-02, 9.0004e-01, 4.3859e-02,\n",
       "                      4.2587e-01, 3.0180e-03, 9.7044e-02, 3.1728e-01, 1.1290e-01, 9.5292e-01,\n",
       "                      9.6720e-01, 8.8839e-01, 7.8914e-01, 2.5573e-01, 7.3123e-01, 8.5053e-01,\n",
       "                      4.5111e-01, 1.6263e-01, 3.1790e-01, 8.2133e-01, 8.0378e-02, 8.2398e-01,\n",
       "                      1.3293e-01, 1.0474e-01, 7.6782e-01, 1.2162e-01, 4.3816e-01, 7.6197e-01,\n",
       "                      8.2074e-01, 8.3583e-02, 5.4986e-01, 4.2268e-02, 2.3532e-01, 4.1361e-01,\n",
       "                      8.5792e-01, 7.7978e-01, 9.3970e-01, 5.0059e-01, 7.1564e-01, 4.6947e-01,\n",
       "                      5.3716e-01, 3.4236e-01, 6.9939e-01, 9.5013e-01, 5.8336e-01, 2.3737e-01,\n",
       "                      1.1947e-01, 9.3981e-01, 3.5707e-01, 5.6808e-01, 8.6056e-02, 4.0112e-01,\n",
       "                      9.4385e-01, 9.8265e-02, 7.0819e-02, 4.0529e-01, 9.6686e-01, 1.2298e-02,\n",
       "                      6.5729e-01, 4.1263e-01, 7.1253e-01, 7.8131e-02, 6.0328e-01, 4.9866e-01,\n",
       "                      3.3808e-01, 8.2102e-01, 4.2510e-02, 4.7893e-03, 5.5511e-01, 5.2618e-01,\n",
       "                      8.4194e-01, 8.6871e-01, 8.7548e-01, 1.4716e-01, 6.1805e-01, 8.5091e-01,\n",
       "                      9.0456e-01, 2.6191e-01, 9.0092e-01, 6.6803e-01, 5.7627e-01, 3.9806e-01,\n",
       "                      9.1824e-01, 6.1736e-01, 7.8363e-01, 4.7602e-01, 2.0122e-01, 5.6401e-01,\n",
       "                      4.9477e-01, 4.1265e-01, 4.5783e-01, 7.6460e-01, 2.3816e-01, 6.4413e-01,\n",
       "                      6.5212e-01, 6.9396e-01], device='cuda:0')),\n",
       "             ('DNN1_net.bn.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.bn.2.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('DNN1_net.ln.0.gamma',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.ln.0.beta',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.ln.1.gamma',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.ln.1.beta',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.ln.2.gamma',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.ln.2.beta',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN1_net.ln0.gamma',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN1_net.ln0.beta',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')),\n",
       "             ('DNN2_net.wx.0.weight',\n",
       "              tensor([[-0.0037,  0.0015,  0.0007,  ..., -0.0039, -0.0029,  0.0032],\n",
       "                      [ 0.0025,  0.0041,  0.0040,  ..., -0.0022, -0.0023,  0.0042],\n",
       "                      [-0.0035,  0.0023, -0.0012,  ...,  0.0021,  0.0006, -0.0028],\n",
       "                      ...,\n",
       "                      [ 0.0039, -0.0034,  0.0034,  ..., -0.0028,  0.0008, -0.0027],\n",
       "                      [-0.0035, -0.0038, -0.0040,  ..., -0.0032,  0.0019,  0.0021],\n",
       "                      [-0.0021,  0.0010,  0.0005,  ..., -0.0024, -0.0038,  0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('DNN2_net.wx.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('DNN2_net.bn.0.weight',\n",
       "              tensor([0.3833, 0.7667, 0.5628, 0.1840, 0.2683, 0.7755, 0.9053, 0.2196, 0.0137,\n",
       "                      0.2547, 0.5684, 0.0040, 0.4878, 0.2251, 0.0087, 0.6966, 0.5303, 0.3113,\n",
       "                      0.6286, 0.4179, 0.8698, 0.1113, 0.6708, 0.0676, 0.4667, 0.7168, 0.6726,\n",
       "                      0.5094, 0.0722, 0.3535, 0.4073, 0.0194, 0.0829, 0.6500, 0.8442, 0.4024,\n",
       "                      0.6538, 0.4707, 0.8240, 0.0783, 0.2223], device='cuda:0')),\n",
       "             ('DNN2_net.bn.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('DNN2_net.bn.0.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('DNN2_net.bn.0.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN2_net.bn.0.num_batches_tracked', tensor(0, device='cuda:0')),\n",
       "             ('DNN2_net.ln.0.gamma',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('DNN2_net.ln.0.beta',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#summary(CNN_net, (1, wlen))\n",
    "\n",
    "Main_net.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
